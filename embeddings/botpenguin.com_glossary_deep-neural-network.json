{"file_name": "botpenguin.com_glossary_deep-neural-network", "text": "URL: https://botpenguin.com/glossary/deep-neural-network\nDeep Neural Networks: Concepts and History Overview\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nDeep Neural Network\nTable of Contents\nWhat are deep neural networks?\nHistory of deep neural networks\nWhy are Deep Neural Networks critical?\nCritical Concepts in Deep Neural Networks\nDeep Neural Network Architecture\nDeep Neural Network Training\nApplications of Deep Neural Networks\nChallenges in Deep Neural Networks\nFuture of Deep Neural Networks\nFAQs\nShare\nLink copied\nWhat are deep neural networks?\nDeep neural networks are a type of machine learning algorithm that is modeled after the structure of the human brain. These networks consist of multiple layers of interconnected nodes or \"neurons\" that work together to process complex information.\nEach layer in the network performs a specific mathematical operation on the input data, and the output of one layer serves as the input for the next layer.\nBy combining and refining information from multiple layers, deep neural networks can identify patterns and relationships in data and make accurate predictions or classifications. They are used in various applications, such as image and speech recognition,\nnatural language processing\n, and autonomous vehicles.\nHistory of deep neural networks\nDNNs have a long and exciting history that dates back to the 1940s when the first artificial neuron was proposed. However, it was not until the 1980s and 1990s that DNNs became popular due to advancements in computer hardware, software, and algorithms. Since then, DNNs have revolutionized many fields and led to significant breakthroughs in\nAI research\n.\nWhy are Deep Neural Networks critical?\nDNNs are essential because they can automate tasks previously thought impossible or difficult for computers to perform. For example, DNNs can recognize faces, translate languages, predict stock prices, and accurately diagnose diseases. Moreover, DNNs can learn from large amounts of data and improve their performance over time, making them ideal for applications that require continuous Learning and adaptation.\nCritical Concepts in Deep Neural Networks\n1. Artificial Neural Networks (ANNs)\nThese are computational models inspired by the structure and function of biological neurons. ANNs consist of an input layer, one or more hidden layers, and an output layer. Each neuron in the network receives inputs, performs a weighted sum of these inputs, applies an activation function to the aggregate, and outputs a signal to the next layer.\n2. Backpropagation\nBackpropagation is a learning algorithm used to adjust the neurons' weights in a DNN to minimize the difference between the predicted and actual outputs. Backpropagation propagates the error backward from the output layer to the input layer and updates the weights using gradient descent.\n3. Convolutional Neural Networks (CNNs)\nCNNs are a DNN type particularly suited for image and video recognition tasks. CNNs use a convolutional operation to extract features from input images and reduce their dimensionality. This operation is followed by pooling, activation, and fully connected layers to classify the images.\n4. Recurrent Neural Networks (RNNs)\nRNNs are a type of DNN designed to handle sequential data such as speech, text, and time series. RNNs use feedback connections to pass information from one time step to the next and can learn long-term dependencies in the data. RNNs can also include memory cells such as Long Short-Term Memory (LSTM) units.\n5. Autoencoders\nAutoencoders are a type of unsupervised DNN that can learn a compressed representation of input data. Autoencoders consist of an encoder that maps the input data to a lower-dimensional model and a decoder that maps the lower-dimensional picture back to the input data. Autoencoders can be used for data compression,\ndenoising\n, and anomaly detection.\n6. Transfer Learning\nTransfer learning is a technique that involves reusing the pre-trained weights of a DNN on a new, related task. Transfer learning can save time and resources compared to training a DNN from scratch and can\nimprove the performance\nof the DNN on the new job.\nDeep Neural Network Architecture\n1. Input Layer\nThe input layer of a DNN is responsible for receiving the raw input data and passing it to the first hidden layer. The input layer can have one or more neurons, depending on the size and dimensionality of the input data.\n2. Hidden Layers\nThe hidden layers of a DNN are responsible for processing the input data and extracting relevant features for the task. The number and size of the hidden layers can vary depending on the complexity of the job and the amount of available data.\n3. Output Layer\nThe output layer of a DNN is responsible for producing the network's final output, which can be a scalar, a vector, or a sequence. The activation function of the output layer depends on the task, but commonly used procedures include softmax for classification tasks and linear or sigmoid for regression tasks.\n4. Activation Functions\nActivation functions are used in the neurons of a DNN to introduce nonlinearity into the network and enable it to learn complex patterns. Popular activation functions include ReLU, sigmoid, tanh, and softmax.\n5. Regularization Techniques\nRegularization techniques are used in DNNs to prevent overfitting, which occurs when the network memorizes the training data instead of learning general patterns. Popular regularization techniques include dropout, batch normalization, and weight decay.\n6. Dropout\nDropout is a regularization technique that randomly drops out some of the neurons in a DNN during training, which forces the remaining neurons to learn more robust features and reduces the risk of overfitting.\n7. Batch Normalization\nBatch normalization is a normalization technique that normalizes the activations of the neurons in a DNN to have zero mean and unit variance. Batch normalization can improve the training speed and stability of the network\nDeep Neural Network Training\n1. Data Preprocessing\nData preprocessing is a crucial step in DNN training that involves cleaning, transforming, and normalizing the input data to improve the performance and convergence of the network. Standard preprocessing techniques include normalization, standardization, and data augmentation.\n2. Loss Functions\nLoss functions are used in DNNs to measure the difference between the predicted and actual outputs of the network. The choice of the loss function depends on the task, but commonly used procedures include mean squared error, cross-entropy, and binary cross-entropy.\n3. Optimizers\nOptimizers are used in DNNs to adjust the weights of the neurons during training to minimize the loss function. Popular optimizers include stochastic gradient descent (SGD), Adam, and Adagrad.\n4. Learning Rate\nThe learning rate is a hyperparameter of DNNs that controls the step size of the weight updates during training. The learning rate can significantly affect the training speed and convergence of the network and should be tuned carefully.\n5. Mini-batch Gradient Descent\nMini-batch gradient descent is a variant of SGD that updates the neurons' weights based on small input data instead of the entire training dataset. Mini-batch GD can speed up the training of DNNs and improve the network's generalization.\n6. Overfitting and Underfitting\nOverfitting and underfitting are common problems in DNN training that occur when the network either memorizes the training data or fails to learn the underlying patterns. Various techniques, such as regularization, early stopping, and model selection can be used to prevent overfitting and underfitting.\n7. Hyperparameter Tuning\nThe process of determining the best settings for a DNN's hyperparameters, such as the number of hidden layers, learning rate, and regularisation strength, is known as hyperparameter tuning.\nHyperparameter tuning can significantly improve the performance and convergence of the network.\nApplications of Deep Neural Networks\n1. Computer Vision\nDNNs have achieved remarkable success in computer vision tasks such as object recognition, face recognition, image segmentation, and object detection. DNN-based computer vision systems are used in various applications, such as autonomous vehicles, surveillance systems, and medical imaging.\n2. Natural Language Processing\nDNNs have also shown great promise in (NLP) tasks such as language translation, sentiment analysis, and speech recognition. DNN-based NLP systems are used in various applications such as virtual assistants, chatbots, and language learning.\n3. Speech Recognition\nDNNs have revolutionized the field of speech recognition by enabling accurate and robust\nspeech-to-text\ntranscription. DNN-based speech recognition systems are used in various applications such as dictation, voice search, and voice-enabled assistants.\n4. Recommender Systems\nDNNs can also be used to build powerful recommender systems that can provide personalized recommendations to users based on their preferences and behavior. DNN-based recommender systems are used in various applications such as e-commerce, music streaming, and\nsocial media\n.\n5. Fraud Detection\nDNNs can also detect and prevent fraud in various industries like finance, insurance, and e-commerce. DNN-based fraud detection systems can analyze large volumes of data to identify patterns and anomalies indicative of fraudulent activity.\n6. Robotics\nDNNs are increasingly used in robotics applications such as object manipulation, motion planning, and autonomous navigation. DNN-based robotic systems can perceive their environment and make intelligent decisions based on the input data.\n7. Gaming\nDNNs can also be used to build intelligent agents to play games such as chess, Go, and video games. DNN-based game-playing agents can learn from experience and improve their performance over time.\n8. Healthcare\nDNNs are used in various healthcare applications such as disease diagnosis, medical imaging, and drug discovery. DNN-based healthcare systems can analyze large amounts of medical data and provide accurate and timely diagnoses and treatments.\nChallenges in Deep Neural Networks\nVanishing and Exploding Gradients\nThe process of identifying hidden patterns, trends, and insights in massive amounts of data is known as data mining. It entails extracting meaningful information from datasets and transforming it into a usable structure for later use. These problems can hinder the convergence and stability of the network and require careful initialization and regularization of the weights.\nOverfitting\nOverfitting is a common problem in DNN training that occurs when the network memorizes the training data instead of learning the underlying patterns. Overfitting can lead to poor generalization and requires various regularization techniques, such as dropout and early stopping, to be addressed.\nAdversarial Attacks\nAdversarial attacks are a type of cyberattack that targets DNNs by introducing subtle perturbations to the input data that can cause the network to misclassify the data. Malicious attacks are a significant concern in security-sensitive applications such as autonomous vehicles and defense systems.\nInterpretability and Explainability\nDNNs are often criticized for being black boxes that are difficult to interpret and explain. This lack of interpretability and explainability can hinder the adoption and trustworthiness of DNN-based systems in various domains such as healthcare and finance.\nFuture of Deep Neural Networks\nAdvancements in Deep Learning\nDeep Learning is a rapidly evolving field constantly pushing the boundaries of what is possible with DNNs. Advances in deep Learning are expected to lead to more powerful and versatile DNNs that can learn from even larger and more complex datasets.\nNeuromorphic Computing\nIt is a new computing paradigm inspired by biological neurons' structure and function. Neuromorphic computing will lead to more efficient and robust DNNs operating in real-time and low-power environments.\nExplainable AI\nExplainable AI is a research field that aims to make DNNs more transparent and interpretable by providing explanations of their decisions and behaviors. Explainable AI is expected to increase the trustworthiness and reliability of DNN-based systems in various domains.\nQuantum Computing\nIt is a new computing paradigm based on the principles of quantum mechanics. Quantum computing is expected to lead to more powerful and faster DNNs that can solve problems currently intractable with classical computing.\nLimitations of Deep Neural Networks\nDespite their impressive performance and potential, DNNs have limitations, such as high computational and energy requirements, dependence on large amounts of data, and inability to reason and abstract. These limitations require new approaches and techniques to be developed to overcome them.\nFAQs\nWhat are Deep Neural Networks (DNNs)?\nDeep Neural Networks are advanced artificial neural networks with multiple hidden layers, enabling complex data representation and improved pattern recognition.\nWhat is the main difference between shallow and deep neural networks?\nExternal neural networks have fewer hidden layers, while deep neural networks contain multiple layers, increasing learning capacity and complex data representation.\nHow do Deep Neural Networks learn?\nDNNs learn by adjusting weights and biases through backpropagation and optimization algorithms, using training data to minimize prediction errors and improve performance.\nWhat are some popular applications of Deep Neural Networks?\nPopular DNN applications include image recognition, natural language processing,\nspeech recognition\n, and game playing, enhancing AI capabilities across various industries.\nWhat are the limitations of Deep Neural Networks?\nDNN limitations include overfitting, high computational requirements, difficulty in training, and the need for large datasets, posing challenges for certain applications.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat are deep neural networks?\nHistory of deep neural networks\nWhy are Deep Neural Networks critical?\nCritical Concepts in Deep Neural Networks\nDeep Neural Network Architecture\nDeep Neural Network Training\nApplications of Deep Neural Networks\nChallenges in Deep Neural Networks\nFuture of Deep Neural Networks\nFAQs\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.12863050401210785, -0.0778084546327591, 0.0341382771730423, 0.008880214765667915, -0.025863587856292725, -0.0235188789665699, 0.026335690170526505, 0.07750463485717773, -0.013249547220766544, -0.000738952832762152, 0.012704059481620789, -0.006067797541618347, -0.006301334127783775, 0.014511778019368649, 0.08101335167884827, -0.017284680157899857, 0.11265967786312103, -0.08052398264408112, -0.11697495728731155, -0.028566576540470123, -0.0003498131118249148, -0.022073782980442047, 0.03880728781223297, -0.036405157297849655, -0.026003163307905197, -0.022075382992625237, -0.026317615061998367, -0.03727896139025688, -0.01778597943484783, -0.05925846844911575, 0.0022969830315560102, 0.008509129285812378, 0.006984282284975052, 0.06335999816656113, -0.03463303670287132, -0.029533041641116142, -0.05160020664334297, 0.013722511939704418, 0.08019887655973434, -0.04986637458205223, -0.07527235150337219, -0.0799698531627655, -0.06549698114395142, 0.009360316209495068, 0.11435854434967041, 0.017189297825098038, -0.0634634718298912, 0.02114500291645527, 0.01729685068130493, 0.09180160611867905, -0.08928954601287842, -0.041317831724882126, 0.041120413690805435, 0.06874741613864899, -0.027635913342237473, 0.0482197031378746, -0.034521762281656265, 0.01784958690404892, 0.006371091585606337, -0.012064782902598381, -0.0362514853477478, -0.012647176161408424, 0.05441567301750183, 0.01584787853062153, -0.028662819415330887, 0.028085505589842796, -0.11649663001298904, 0.01020924560725689, 0.010410478338599205, -0.02337534911930561, 0.020540056750178337, 0.01576894521713257, -0.04259270429611206, 0.054823197424411774, -0.00775217404589057, -0.018454503268003464, 0.030898921191692352, -0.008642424829304218, 0.01691989041864872, -0.07616367936134338, 0.009240999817848206, 0.061847470700740814, 0.0002886751026380807, 0.051601897925138474, -0.014756101183593273, -0.044731151312589645, -0.016169503331184387, 0.03689776733517647, -0.057491499930620193, -0.012423145584762096, 0.02406756579875946, 0.00011250788520555943, 0.0182314682751894, 0.0020487059373408556, 0.04521528258919716, 0.02193521521985531, -0.07821359485387802, 0.011800401844084263, -0.06701279431581497, -0.003969228360801935, -0.008268643170595169, -0.04100780934095383, -0.04392428696155548, -0.08605023473501205, -0.03919066861271858, 0.02518501691520214, 0.07348096370697021, -0.013231378048658371, 0.15373754501342773, -0.014814735390245914, -0.11824867129325867, -0.04705951362848282, -0.001017807051539421, -0.02010972425341606, 0.021026356145739555, 0.017079733312129974, -0.042402129620313644, 0.04889495670795441, 0.1267535239458084, 0.050760313868522644, 0.021231260150671005, 0.050873760133981705, -0.0056973970495164394, -0.00551175931468606, 0.032667938619852066, 0.030687808990478516, -0.029881607741117477, 1.0453187105126858e-32, -0.04330580309033394, 0.02913101390004158, -0.06267079710960388, 0.08366479724645615, 0.04908590391278267, 0.022016305476427078, 0.02083498053252697, 0.054613664746284485, -0.06891996413469315, -0.017122121527791023, -0.11796381324529648, 0.1065661609172821, -0.08124259859323502, 0.06825307756662369, 0.013388439081609249, -0.0896884873509407, -0.009322095662355423, 0.00870391633361578, 0.06567323952913284, -0.02172328345477581, 0.0850139856338501, -0.02050282247364521, 0.06246107816696167, 0.07853128761053085, 0.1218985915184021, 0.0041726515628397465, 0.08256323635578156, 0.0232682004570961, 0.04754287376999855, 0.02147742547094822, -0.10023798793554306, 0.009838801808655262, -0.04561934620141983, 0.014055019244551659, -0.03511374071240425, -0.037652138620615005, -0.038964785635471344, -0.10310152173042297, -0.061067283153533936, 0.022513514384627342, -0.12030530720949173, 0.006524034775793552, -0.10359800606966019, -0.06980033963918686, 0.007636019494384527, -0.0016145294066518545, 0.019864460453391075, 0.016612593084573746, 0.016880108043551445, 0.02283899299800396, -0.050022050738334656, 0.024557536467909813, 0.022945299744606018, 0.017712995409965515, -0.0008705126820132136, -0.03446409851312637, 0.05019523948431015, -0.02004479058086872, 0.007086572702974081, -0.020146997645497322, -0.005048264749348164, -0.03448401391506195, -0.01624702848494053, -0.015112442895770073, 0.03327126055955887, 0.033740077167749405, 0.0533437505364418, 0.04859109967947006, 0.03996936231851578, 0.023325201123952866, 0.04409191384911537, 0.06194327399134636, -0.011592506431043148, 0.02602001652121544, -0.03619160130620003, 0.033538032323122025, -0.09124130010604858, 0.012274839915335178, -0.06139357015490532, 0.018047437071800232, -0.012903810478746891, 0.023185161873698235, -0.016513682901859283, -0.016179868951439857, 0.05302060395479202, 0.0038285807240754366, 0.038637369871139526, -0.04193367063999176, -0.002212418243288994, 0.057295478880405426, -0.03815598785877228, 0.07183757424354553, -0.060860101133584976, 0.05616200715303421, -0.03599761426448822, -8.026096899210048e-33, -0.03598522022366524, 0.04694826528429985, -0.08317853510379791, 0.09240902215242386, 0.026889899745583534, -0.020686021074652672, 0.002541177673265338, -0.03748101741075516, 0.07370269298553467, 0.0060211410745978355, -0.07530268281698227, -0.024508077651262283, 0.018195001408457756, -0.047875694930553436, -0.0027943176683038473, 0.016036586835980415, -0.07800912857055664, -0.05062257498502731, 0.028073912486433983, 0.004336479585617781, -0.015546205453574657, 0.06113263592123985, -0.13856419920921326, -0.0009443311719223857, -0.021042916923761368, 0.03251807764172554, -0.08289523422718048, 0.07803753018379211, 0.01855071261525154, 0.015799198299646378, -0.02707250602543354, -0.024011939764022827, -0.04433451220393181, 0.003254170995205641, 0.022014794871211052, 0.0758354589343071, 0.041272856295108795, -0.032231803983449936, -0.016716761514544487, -0.06821813434362411, 0.10016109049320221, -0.06026086583733559, -0.03562135621905327, -0.06609237194061279, -0.01592961512506008, 0.0239731315523386, -0.15068678557872772, -0.024512451142072678, -0.053824007511138916, 0.049806538969278336, 0.0603422112762928, -0.005532506853342056, 0.03238392248749733, -0.044032175093889236, -0.08916422724723816, -0.03503173589706421, 0.09267838299274445, 0.021066291257739067, -0.06279528141021729, 0.04737817123532295, 0.0163703765720129, -0.01060025580227375, 0.06470432132482529, 0.06384877115488052, 0.01642664521932602, -0.007823416963219643, 0.0462031252682209, 0.05374862626194954, -0.0016423360211774707, -0.09244242310523987, 0.0401780940592289, -0.056912049651145935, 0.005489017348736525, 0.03284416347742081, -0.005345012992620468, 0.06969042122364044, 0.02662539668381214, -0.11007051169872284, 0.012561150826513767, -0.034571047872304916, -0.05068107321858406, -0.014130042865872383, 0.0426785945892334, 0.06271132826805115, -0.051572926342487335, 0.0910697728395462, -0.016840212047100067, 0.022831618785858154, 0.007459519896656275, 0.011228063143789768, -0.035951871424913406, 0.016663670539855957, -0.029402196407318115, 0.08150525391101837, -0.008708490058779716, -5.783449097407356e-08, -0.039800286293029785, 0.015758920460939407, 0.060518138110637665, 0.04923628643155098, 0.05169050022959709, -0.08495870977640152, -0.03127949684858322, 0.09408684819936752, 0.036968208849430084, 0.03309357911348343, 0.03298567607998848, -0.029420915991067886, -0.080338254570961, 0.05011453479528427, 0.04709620773792267, 0.007151029072701931, -0.0076234000734984875, -0.022093169391155243, 0.04600101336836815, -0.023323796689510345, 0.08342641592025757, 0.033784929662942886, -0.03201131522655487, -0.009915245696902275, 0.03513246774673462, -0.0772494226694107, -0.060138870030641556, 0.08968844264745712, -0.03946446254849434, -0.004313039593398571, -0.020523564890027046, -0.016574086621403694, 0.06412015110254288, -0.05824127420783043, 0.026094600558280945, 0.01774263195693493, -0.0626947283744812, -0.06553296744823456, 6.088334703235887e-05, 0.03247421234846115, 0.011744536459445953, 0.03935066610574722, 0.029541054740548134, -0.09034634381532669, -0.036417655646800995, -0.06091612949967384, -0.06291849166154861, -0.11229882389307022, 0.05921695753931999, 0.005465700291097164, -0.058167167007923126, 0.02156618982553482, 0.0592769980430603, 0.051625169813632965, 0.07957638055086136, -0.01794513873755932, 0.06845442950725555, -0.03316759690642357, 0.07509751617908478, 0.1359325796365738, 0.018456799909472466, 0.02653454802930355, 0.0041840653866529465, 0.02667984366416931]}