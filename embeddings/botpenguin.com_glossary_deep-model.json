{"file_name": "botpenguin.com_glossary_deep-model", "text": "URL: https://botpenguin.com/glossary/deep-model\nAn Overview of Data Model Types | BotPenguin\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nDeep Model\nTable of Contents\nWhat are Deep Models?\nTypes of Deep Models\nChallenges and Limitations of Deep Models\nTraining Deep Models\nApplications of Deep Models\nChallenges and Limitations of Deep Models\nFAQs\nShare\nLink copied\nWhat are Deep Models?\nDeep Models are a type of\nmachine learning alg\norithm that use artificial neural networks with multiple layers to extract high-level features from input data. This means that the model is able to learn and identify complex patterns and relationships within the data, making it particularly effective in solving difficult problems such as speech recognition, natural language processing, and computer vision.\nThe depth of the model refers to the multiple layers of interconnected neurons used to process the input data. Each layer is designed to extract and transform specific features from the input data using a combination of weights and biases. As the input data is passed through the layers, the model adjusts the weights and biases to optimize its predictions, resulting in increasingly accurate results.\nTypes of Deep Models\n1. Convolutional Neural Networks (CNN)\nConvolutional Neural Networks (CNNs) are a type of deep neural network that use convolutional layers to process images. They're commonly used for image classification, but can also be applied to other tasks such as object detection and segmentation.\n2. Recurrent Neural Networks (RNN)\nRecurrent Neural Networks (RNNs) are another type of deep neural network that can learn long-term dependencies between data points in sequences or time series.\nRNNs have been applied in natural language processing tasks like machine translation and speech recognition because they can deal with variable length inputs and output sequences without requiring any additional training data beyond what's available during runtime execution--a process known as \"backpropagation through time\" (BPTT).\n3. Natural Language Processing (NLP)\nNatural Language Processing (NLP) is another common application of deep models, and involves processing and understanding human language. Deep models such as Recurrent Neural Networks (RNNs) and Transformer models have achieved state-of-the-art performance on many NLP tasks such as language modeling, sentiment analysis, and machine translation. For example, the famous GLUE benchmark is a yearly competition to evaluate the performance of NLP models on a variety of tasks, and deep models have consistently outperformed other models on this benchmark.\n4. Speech Recognition\nSpeech recognition is another common application of deep models, and involves recognizing and transcribing human speech into text. Deep models such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have achieved state-of-the-art performance on many speech recognition tasks such as keyword spotting, speaker identification, and speech-to-text transcription. For example, the famous LibriSpeech dataset is a collection of over 1,000 hours of spoken text, and deep models have achieved high accuracy rates on this dataset.\nUnlock the potential of Deep Model\nUncover the Secrets\nChallenges and Limitations of Deep Models\n1. Insufficient Data Availability\nA major obstacle in deep models is the scarcity of available data. Deep learning models need a substantial amount of data to effectively identify and generalize patterns.\nHowever, obtaining labeled data can be a lengthy, costly, and difficult process in specific fields, hindering the efficiency of deep models in certain applications.\n2. Computational Demands\nDeep learning models necessitate considerable computational resources, such as high-performance CPUs and GPUs, for training and execution.\nThis may restrict the accessibility of deep learning for individuals and organizations lacking these resources. Furthermore, the substantial computational expense of deep learning can constrain the scalability of models, particularly in real-time applications.\n3. Prone to Overfitting\nA prevalent issue with deep learning models is overfitting. Overfitting happens when a model excels in training data but underperforms in test data.\nOverfitting can arise when a model is overly complex or when there is not enough training data.\nWhile regularization techniques can help mitigate overfitting, they might also decrease the model's accuracy on the training data.\n4. Lack of Interpretability\nAnother drawback of deep learning models is their lack of interpretability. Deep learning models can be hard to decipher, making it difficult to comprehend their decision-making processes.\nThis can pose problems in areas where interpretability is essential, such as\nhealthcare\nor finance. Exploring methods for interpreting deep learning models is a current research focus.\n5. Issues with Generalization\nGeneralization pertains to a model's capability to perform well on data beyond the training distribution. Deep learning models may have difficulties with generalization, particularly when the training data is inadequate or biased.\nThis can restrict the usefulness of deep learning models in fields where the data distribution continuously changes or where data exhibits significant variability.\nTraining Deep Models\n1. Backpropagation\nBackpropagation is a type of optimization algorithm that is used to train deep models by minimizing the difference between the predicted output and the actual output. It works by propagating the error from the output layer to the input layer and adjusting the weights and biases of each neuron along the way. Backpropagation is a computationally intensive and can suffer from issues such as vanishing gradients and overfitting.\n2. Gradient Descent\nGradient descent is an optimization algorithm used in\nmachine learning\nto minimize the loss function of a model. It is a first-order optimization algorithm that works by iteratively adjusting the parameters of a model in the direction of steepest descent of the cost or loss function.\nThe algorithm begins by calculating the gradient of the loss function with respect to the model parameters. The gradient provides information about the direction of steepest descent, allowing the algorithm to adjust the parameters in a way that reduces the loss function. The size of the adjustment is determined by the learning rate, which controls the step size taken in the direction of the gradient.\n3. Regularization\nRegularization is a set of techniques that prevent overfitting in deep models by adding constraints to the weights and biases of each neuron. Several types of regularization techniques, such as L1 regularization, L2 regularization, Dropout, and Batch Normalization, each with their strengths and weaknesses.\nApplications of Deep Models\n1. Image Recognition\nIt is one of the most common applications of deep models. It involves recognizing objects, scenes, and patterns in images. Deep models such as Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance on image recognition tasks such as object detection, image segmentation, and image classification. For example, the famous ImageNet challenge is a yearly competition to classify images into 1,000 categories. CNNs have consistently outperformed other models on this task.\n2. Natural Language Processing (NLP)\nNatural Language Processing (NLP) is another common application of deep models and involves processing and understanding human language. Deep models such as Recurrent Neural Networks (RNNs) and Transformer models have achieved state-of-the-art performance on many NLP tasks such as language modeling, sentiment analysis, and machine translation. For example, the famous GLUE benchmark is a yearly competition to evaluate the performance of NLP models on various tasks, and deep models have consistently outperformed other models on this benchmark.\n3. Speech Recognition\nSpeech recognition is another common application of deep models and involves recognizing and transcribing human speech into text. Deep models such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have achieved state-of-the-art performance on many speech recognition tasks such as keyword spotting, speaker identification, and speech-to-text transcription. For example, the famous LibriSpeech dataset is a collection of over 1,000 hours of spoken text, and deep models have achieved high accuracy rates on this dataset.\nChallenges and Limitations of Deep Models\n1. Overfitting\nOverfitting is a common challenge in deep models. It occurs when the model is too complex and fits the training data too well, leading to poor generalization performance on new data. To prevent overfitting, regularization techniques such as L1 and L2 regularization, Dropout, and Early Stopping can be used, as well as data augmentation and model ensembling.\n2. Vanishing Gradient\nVanishing Gradient is another common challenge in deep models and occurs when the gradients become very small and fail to update the weights and biases of the neurons in the lower layers, leading to slow or no learning. To prevent vanishing Gradient, initialization techniques such as Xavier and He initialization, activation functions such as ReLU and variants, and optimization algorithms such as AdaGrad and RMSProp can be used.\n3. Interpretability\nInterpretability is a major limitation of deep models. It refers to the difficulty of understanding and explaining how the model makes its predictions. Deep models are often viewed as \"black boxes\" due to their high complexity and non-linearity, and extracting meaningful insights from them can be difficult. However, several techniques, such as visualization, attribution, and explanation methods, are being developed to improve the interpretability of deep models.\nFAQs\n1. What is a Deep Model in machine learning?\nA Deep Model is a\nmachine learning\ntechnique that uses artificial neural networks with multiple layers to extract high-level features from input data, improving prediction accuracy.\n2. How do Deep Models differ from shallow models?\nDeep Models have multiple hidden layers and can learn complex patterns, while shallow models have fewer layers and limited capacity to capture intricate relationships in data.\n3. What are common applications of Deep Models?\nDeep Models are used in image and speech recognition, natural language processing, sentiment analysis, and recommendation systems, among other applications.\n4. What are the primary challenges in training Deep Models?\nTraining Deep Models can be challenging due to the large amount of data and computational power required, risk of overfitting, and vanishing or exploding gradient problems.\n5. Are Deep Models always better than shallow models?\nDeep Models excel in certain applications but aren't always better. Shallow models can be more efficient and accurate for simpler tasks with less data and less computational resources.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat are Deep Models?\nTypes of Deep Models\nChallenges and Limitations of Deep Models\nTraining Deep Models\nApplications of Deep Models\nChallenges and Limitations of Deep Models\nFAQs\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.10419191420078278, -0.0946752056479454, 0.029267214238643646, 0.018335353583097458, -0.037335582077503204, -0.05053999647498131, 0.02383977547287941, 0.08008241653442383, 0.00550705986097455, 0.028066879138350487, 0.03528926521539688, -0.0211336687207222, 0.01389258075505495, 0.019586671143770218, 0.11810781806707382, -0.00967966578900814, 0.12353845685720444, -0.10169990360736847, -0.11446361243724823, -0.02768130786716938, 0.0056452020071446896, -0.02045043185353279, 0.027469271793961525, -0.0373525395989418, -0.03619878366589546, -0.03739972040057182, -0.024410955607891083, -0.024724818766117096, -0.011927904561161995, -0.08266448974609375, -0.028041910380125046, 0.028799304738640785, 0.004361964762210846, 0.06390805542469025, -0.012221056036651134, -0.04668721556663513, -0.03251377493143082, 0.01640566624701023, 0.07617661356925964, -0.04405838996171951, -0.06828940659761429, -0.08854235708713531, -0.055957190692424774, 0.005958072375506163, 0.0984296202659607, -0.008450180292129517, -0.07048948854207993, 0.013269219547510147, 0.009832179173827171, 0.07998920977115631, -0.09237031638622284, -0.041747357696294785, 0.02653536945581436, 0.07561709731817245, -0.018613355234265327, 0.03100387006998062, -0.03260693699121475, 0.005059224087744951, 0.01773562841117382, -0.00260841753333807, -0.04365989938378334, 0.002984048333019018, 0.03474743664264679, 0.028980016708374023, -0.023299070075154305, 0.030144495889544487, -0.13009819388389587, 0.012766139581799507, 0.0024877891410142183, -0.02083984948694706, -0.007152273319661617, -0.021352987736463547, -0.058881767094135284, 0.04071621224284172, 0.014372645877301693, -0.04984162002801895, 0.022327031940221786, -0.0006565619260072708, 0.026329249143600464, -0.06637006253004074, -0.016768382862210274, 0.062123194336891174, -0.009078407660126686, 0.05693015828728676, -0.020089704543352127, -0.04228384420275688, -0.005926426965743303, 0.034650884568691254, -0.0362640917301178, -0.008887840434908867, 0.025893280282616615, -0.004225702956318855, 0.030569691210985184, 0.020779544487595558, 0.03143133968114853, 0.026112666353583336, -0.051889367401599884, 0.01516902819275856, -0.05178418755531311, 0.00023728951055090874, -0.00460542319342494, -0.030769944190979004, -0.04311955347657204, -0.07424157112836838, -0.04837043955922127, -0.005073818378150463, 0.06662815809249878, -0.013351577334105968, 0.13126951456069946, -0.00024459086125716567, -0.1239716112613678, -0.04753381386399269, -0.003168192459270358, -0.027187546715140343, 0.012268869206309319, 0.005320439580827951, -0.055989254266023636, 0.052683304995298386, 0.13099506497383118, 0.03498385474085808, 0.039870116859674454, 0.056139569729566574, 0.01644604466855526, -0.0049135275185108185, 0.043037284165620804, 0.030815567821264267, -0.018726615235209465, 1.0972776179341448e-32, -0.03312990069389343, 0.03375504910945892, -0.057579156011343, 0.09525143355131149, 0.04146692901849747, 0.028810827061533928, 0.0053487904369831085, 0.05298412963747978, -0.06400832533836365, 0.0023850882425904274, -0.11546450108289719, 0.11416135728359222, -0.10340506583452225, 0.06362682580947876, 0.03188561275601387, -0.0699663907289505, -0.026872850954532623, 0.03692040592432022, 0.04421002045273781, 0.005358471069484949, 0.10860458016395569, -0.016449442133307457, 0.059165988117456436, 0.06896781921386719, 0.14454469084739685, 0.030385127291083336, 0.07577573508024216, 0.02312498912215233, 0.030122384428977966, 0.039661917835474014, -0.08366785943508148, 0.004608072340488434, -0.03931751474738121, 0.019100729376077652, -0.05023879185318947, -0.02846056967973709, -0.03452715650200844, -0.11387492716312408, -0.057993508875370026, 0.008678172715008259, -0.12251749634742737, 0.01332133263349533, -0.10491879284381866, -0.07221247255802155, 0.0033993113320320845, 0.010001459158957005, 0.03471430391073227, 0.008783387020230293, 0.014070196077227592, 0.02422046847641468, -0.033014927059412, 0.018312666565179825, 0.0319308303296566, 0.037750646471977234, -0.013876949436962605, -0.02838790789246559, 0.04985514655709267, -0.03077290579676628, 0.0016853827983140945, -0.0076690902933478355, -0.02166302129626274, -0.02691102959215641, 0.00237379246391356, -0.023715512827038765, 0.06371138244867325, 0.03174392879009247, 0.03977701812982559, 0.01925259456038475, 0.05607963353395462, 0.025240613147616386, 0.030527740716934204, 0.05553165078163147, -0.0341370590031147, 0.03321557119488716, -0.029040366411209106, -0.007359566166996956, -0.09532127529382706, 0.011600453406572342, -0.051242947578430176, 0.004249284975230694, -0.02888752520084381, 0.004953491035848856, -0.025625599548220634, -0.02676273137331009, 0.0469270795583725, -0.016819993034005165, 0.02753428928554058, -0.039744820445775986, -0.014954802580177784, 0.037253838032484055, -0.05103432387113571, 0.07290667295455933, -0.07253779470920563, 0.061001572757959366, -0.033587321639060974, -8.966299892667931e-33, -0.04482102021574974, 0.024288762360811234, -0.07121644914150238, 0.08978606760501862, 0.029764879494905472, -0.05045289173722267, 0.035169076174497604, -0.03868565708398819, 0.09087714552879333, -0.004982661455869675, -0.08687296509742737, -0.022038577124476433, 0.022932177409529686, -0.03580666333436966, 0.0038464439567178488, 0.011441650800406933, -0.07241451740264893, -0.06813511997461319, 0.017321772873401642, 0.012307279743254185, -0.0330432653427124, 0.05107155814766884, -0.13700902462005615, 0.003261963836848736, -0.01125404890626669, 0.04828983172774315, -0.09845416992902756, 0.05893838778138161, 0.03319713845849037, 0.014934194274246693, -0.027992310002446175, -0.014128772541880608, -0.02588583528995514, -0.005647240672260523, -0.008291433565318584, 0.05285387486219406, 0.03666531294584274, -0.018976395949721336, -0.010352746583521366, -0.048458706587553024, 0.08986519277095795, -0.053909845650196075, -0.04292125254869461, -0.06838512420654297, -0.006415945943444967, 0.03812956064939499, -0.14064793288707733, -0.03317825123667717, -0.03847039118409157, 0.02396072819828987, 0.05916394293308258, 0.008386979810893536, 0.0335734561085701, -0.03303435444831848, -0.09496469050645828, -0.03804662451148033, 0.0924963653087616, -0.007100815884768963, -0.08781372010707855, 0.031379587948322296, 0.01788824237883091, -0.005845998413860798, 0.06501457095146179, 0.08360231667757034, 0.028608227148652077, -0.024745319038629532, 0.05056290328502655, 0.013399511575698853, -0.013907802291214466, -0.09936178475618362, 0.043846648186445236, -0.05379790440201759, -0.0014294026186689734, 0.010900366120040417, 0.023935595527291298, 0.05310961231589317, 0.023697886615991592, -0.10188159346580505, 0.027976911514997482, -0.027103401720523834, -0.073973149061203, -0.0037794432137161493, 0.06349392235279083, 0.05982787907123566, -0.07168964296579361, 0.06361857801675797, -0.020460540428757668, 0.02231934666633606, -0.013877307996153831, 0.017935510724782944, -0.062114715576171875, 0.02489468827843666, -0.031858012080192566, 0.09948393702507019, -0.01316886581480503, -6.081879888597541e-08, -0.03445475548505783, 0.014679301530122757, 0.06498578935861588, 0.049418382346630096, 0.04080613702535629, -0.07011160999536514, -0.04906689375638962, 0.09412411600351334, 0.04230921342968941, 0.042475227266550064, 0.02686493471264839, -0.014188499189913273, -0.06573789566755295, 0.06674478203058243, 0.06810696423053741, 0.014531278982758522, 0.004226514603942633, -0.024396153166890144, 0.023255564272403717, -0.025319920852780342, 0.07814116775989532, 0.03338173031806946, -0.04027668014168739, -0.02866712585091591, 0.052665844559669495, -0.06635252386331558, -0.07806166261434555, 0.09580982476472855, -0.040002550929784775, 0.012870986945927143, -0.01811923272907734, -0.024853114038705826, 0.062209490686655045, -0.037054721266031265, 0.006617895793169737, 0.01792602799832821, -0.04883524775505066, -0.07046784460544586, 0.009939681738615036, 0.03525759279727936, 0.027708588168025017, 0.030594835057854652, -0.0032392239663749933, -0.08006138354539871, -0.004436856601387262, -0.0437760092318058, -0.06130905821919441, -0.12206605076789856, 0.050940584391355515, 0.014508143067359924, -0.06633065640926361, 0.01421397179365158, 0.05054904893040657, 0.04908651113510132, 0.07034385949373245, 0.0020191872026771307, 0.06001175567507744, -0.015418102033436298, 0.09140940755605698, 0.10338529199361801, 0.033814217895269394, 0.010726053267717361, 0.012409179471433163, 0.02733118087053299]}