{"file_name": "botpenguin.com_glossary_variational-autoencoder", "text": "URL: https://botpenguin.com/glossary/variational-autoencoder\nWhat is Variational Autoencoder & how it works | BotPenguin\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nVariational Autoencoder\nTable of Contents\nWhat is a Variational Autoencoder?\nHow does a Variational Autoencoder work?\nWhy are Variational Autoencoders useful?\nWhat is a Variational Autoencoder used for?\nWhat is the difference between Autoencoder and Variational Autoencoder?\nWhat is the most crucial drawback of Variational Autoencoders?\nVariational Autoencoder in Practice\nVariational Autoencoder Challenges and Future Developments\nFrequently Asked Questions (FAQs)\nShare\nLink copied\nWhat is a Variational Autoencoder?\nA Variational Autoencoder (VAE) is a type of neural network architecture that combines elements of both an autoencoder and a probabilistic model. It is designed to learn a compressed representation of input data while also capturing the underlying probability distribution of the data.\nUnlike traditional autoencoders, VAEs introduce a stochastic element to the encoder, allowing for the generation of new data samples through random sampling in the latent space.\nHow does a Variational Autoencoder work?\nHere\u2019s how it works:\nThe input data is encoded by the encoder network, mapping it into the latent space distribution. The decoder network takes a sample from the latent space distribution and reconstructs the original input data.\nThe latent space distribution is regularized to follow a predefined prior distribution by minimizing the Kullback-Leibler (KL) divergence between the learned distribution and the prior distribution.\nStep-by-Step Explanation of Training Process\nEncoding\nThe encoder network maps the input data to the latent space distribution, typically modelled as a multivariate Gaussian. It consists of fully connected layers, with the mean and variance outputs representing the parameters of the latent distribution.\nDecoding\nThe decoder network takes a sample from the latent space distribution and reconstructs the original input data. It mirrors the encoder architecture but in reverse order.\nReconstruction Loss\nThe reconstruction loss measures the similarity between the original input data and its reconstruction. It encourages the autoencoder to minimize the discrepancies between the two.\nRegularization\nThe KL divergence between the learned latent distribution and the predefined prior distribution is minimized to regularize the latent space. This encourages the distribution of latent vectors to follow the desired prior.\nLoss Function and Optimization\nThe reconstruction loss and the regularization term are combined into a single loss function. Gradient descent optimization algorithms, such as Adam or SGD, are used to iteratively update the encoder and decoder weights to minimize this loss.\nSampling and Generation\nTrained Variational Autoencoders can generate new data samples by sampling from the learned latent space distribution.\nRandom points in the latent space are selected and decoded by the decoder network, resulting in the generation of novel data samples.\nBy following these steps, a Variational Autoencoder is able to learn a compressed representation of input data while capturing the underlying probability distribution.\nUse Your Companion for Business\nGet Started FREE\nWhy are Variational Autoencoders useful?\nVariational Autoencoders offer several advantages that make them highly useful for generative modelling tasks:\nContinuous latent space\nThe latent space in Variational Autoencoders is continuous and follows a probabilistic distribution, allowing for smooth interpolation between different data points.\nThis enables the generation of new data samples by sampling from the latent space.\nAbility to perform random sampling and interpolation\nBy sampling random points from the latent space distribution, Variational Autoencoders can generate diverse and novel data samples.\nAdditionally, the smoothness of the latent space allows for meaningful interpolation between existing data points to create new, realistic samples.\nImproved organization of the latent space\nThe regularization term encourages the latent space to follow the desired prior distribution, leading to an organized and\nstructured representation of the data\n.\nThis can facilitate tasks such as data exploration, anomaly detection, and\nclustering\n.\nWhat is a Variational Autoencoder used for?\nVariational Autoencoders find applications in various domains, including:\nGenerative modeling\nVariational Autoencoders can generate new data samples by sampling from the learned latent space distribution.\nThis makes them useful for tasks such as image synthesis, text generation, and music composition.\nData compression\nVariational Autoencoders learn a compressed representation of the input data in the latent space.\nThis can be beneficial for tasks that involve reducing the dimensionality or compressing large\ndatasets\n.\nAnomaly detection\nBy learning the underlying distribution of the input data, Variational Autoencoders can identify patterns that deviate from the norm.\nThis makes them suitable for detecting anomalies or outliers in\ndatasets\n.\nClustering and visualization\nThe organized representation of the latent space in Variational Autoencoders allows for meaningful clustering of data points.\nThis facilitates data exploration and visualization, aiding in\npattern recognition\nand analysis.\nWhat is the difference between Autoencoder and Variational Autoencoder?\nA Variational Autoencoder differs from a traditional autoencoder in several ways:\nEncoding of the latent space\nIn a traditional autoencoder, the latent space serves as an arbitrary encoding of the input data with no explicit probabilistic interpretation.\nIn contrast, a Variational Autoencoder models the latent space as a distribution, typically a multivariate Gaussian, allowing for sampling and generation of new data points.\nRegularization of the latent space\nVariational Autoencoders introduce regularization in the latent space through the minimization of the KL divergence between the learned latent distribution and a predefined prior distribution.\nThis encourages the latent space to follow a desired probabilistic structure.\nGeneration of new data\nVariational Autoencoders can generate new data samples by sampling from the learned latent space distribution. Traditional autoencoders lack this ability.\nWhat is the most crucial drawback of Variational Autoencoders?\nWhile Variational Autoencoders have proven to be powerful generative models, they do suffer from a common drawback:\nThe generated samples from a Variational Autoencoder can sometimes appear blurry and lacking in realism. This is often due to the trade-off between reconstruction accuracy and the regularization of the latent space.\nThe regularization term can constrain the latent space distribution, resulting in a smoothing effect that reduces the fine details present in the original data.\nVariational Autoencoder in Practice\nVariational Autoencoders have found success in a wide range of domains:\nImage generation\nVariational Autoencoders have been used to generate realistic images across different domains, such as faces, handwritten digits, and landscapes.\nText generation\nVariational Autoencoders can generate coherent and contextually relevant text, making them useful for tasks such as dialogue generation, story generation, and\nlanguage translation\n.\nDrug discovery\nVariational Autoencoders have been employed in drug discovery pipelines to generate novel chemical compounds with desired properties.\nMusic Composition\nVariational Autoencoders can generate new musical compositions, capturing the underlying structure and patterns within the\ntraining data\n.\nVariational Autoencoder Challenges and Future Developments\nWhile Variational Autoencoders have shown great promise, there are still some challenges and limitations to be addressed:\nDifficulties in modelling complex distributions\nVariational Autoencoders struggle to model particularly complex or multimodal distributions due to the limitations of the Gaussian assumption for the latent space.\nTrade-off between accuracy and diversity\nBalancing the reconstruction accuracy and the diversity of generated samples is an ongoing challenge in Variational Autoencoder research.\nIncreasing the regularization term to improve diversity can lead to a decrease in reconstruction accuracy.\nLarge-scale deployment\nScaling Variational Autoencoders to\nlarge datasets\nand real-time applications can be computationally expensive and time-consuming.\nBuilding Better Businesses with Bots\nTry BotPenguin\nFrequently Asked Questions (FAQs)\nHow does a Variational Autoencoder differ from a traditional autoencoder?\nA Variational Autoencoder models the latent space as a distribution, enabling the generation of new data points. In contrast, a traditional autoencoder treats the latent space as an arbitrary encoding of the input data.\nCan Variational Autoencoders be used for unsupervised learning tasks?\nYes, Variational Autoencoders can be used for unsupervised learning tasks. They can learn meaningful representations of input data without the need for labelled training data.\nAre Variational Autoencoders suitable for high-dimensional data?\nYes, Variational Autoencoders can handle high-dimensional data. The continuous latent space representation allows for effective compression and reconstruction of high-dimensional input data.\nCan Variational Autoencoders be used for anomaly detection?\nYes, Variational Autoencoders can be used for anomaly detection. By comparing the reconstruction error between the input data and its reconstruction, unusual or anomalous samples can be identified.\nHow do Variational Autoencoders handle missing data?\nVariational Autoencoders can handle missing data by training the model to reconstruct input data even when some values are missing. The reconstruction loss helps guide the model in filling in the missing values.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat is a Variational Autoencoder?\nHow does a Variational Autoencoder work?\nWhy are Variational Autoencoders useful?\nWhat is a Variational Autoencoder used for?\nWhat is the difference between Autoencoder and Variational Autoencoder?\nWhat is the most crucial drawback of Variational Autoencoders?\nVariational Autoencoder in Practice\nVariational Autoencoder Challenges and Future Developments\nFrequently Asked Questions (FAQs)\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.1056302860379219, -0.08201293647289276, 0.015911877155303955, 0.009642114862799644, -0.029669756069779396, -0.015415342524647713, 0.025692293420433998, 0.06711999326944351, -0.008291377685964108, -0.0030105486512184143, 0.03421134874224663, -0.024751029908657074, 0.016527747735381126, 0.016817642375826836, 0.09667438268661499, 0.0011626193299889565, 0.1023973748087883, -0.08925340324640274, -0.10596148669719696, -0.054679203778505325, -0.007683099713176489, -0.0016999411163851619, 0.021108774468302727, -0.022138193249702454, -0.0029618870466947556, -0.042095668613910675, -0.027114996686577797, 0.002153861802071333, 0.010812715627253056, -0.0699315220117569, 0.005495305173099041, 0.04813459888100624, 0.00442965654656291, 0.07969362288713455, -0.02507469244301319, -0.05355002358555794, -0.05794853717088699, 0.02144954912364483, 0.0683106854557991, -0.062156565487384796, -0.0906720981001854, -0.0794307291507721, -0.07415923476219177, 0.020462369546294212, 0.07797542214393616, -0.005425266921520233, -0.0653909370303154, -0.009075719863176346, -0.007280960213392973, 0.061957430094480515, -0.09160229563713074, -0.035666752606630325, 0.030147366225719452, 0.03155386820435524, -0.057174086570739746, 0.010305681265890598, -0.0072916848585009575, 0.01808471791446209, 0.05463398993015289, -0.008332980796694756, -0.04561629891395569, -0.011890437453985214, 0.046695277094841, 0.031704891473054886, -0.04742266610264778, 0.0197585616260767, -0.09246698766946793, -0.007450011558830738, 0.014244942925870419, -0.05189655348658562, -0.023865895345807076, -0.026886330917477608, -0.05007819086313248, 0.06601326167583466, 0.02093985676765442, -0.040363624691963196, 0.0103646544739604, -0.020915325731039047, 0.05069420114159584, -0.08054394274950027, -0.03548257052898407, 0.009418814443051815, -0.004513744730502367, 0.09295632690191269, -0.007605273276567459, -0.0328475646674633, 0.0016206889413297176, 0.036608707159757614, -0.009144200012087822, 0.02659885585308075, 0.006012441590428352, -0.018560810014605522, 0.020396389067173004, 0.0111188143491745, 0.03496183827519417, 0.01002521626651287, -0.05731343850493431, -0.0026874379254877567, -0.02572742849588394, -0.0005583185120485723, -0.0015144088538363576, -0.04314279928803444, -0.04703738912940025, -0.07548823207616806, -0.048947084695100784, -0.005959716159850359, 0.07719168812036514, -0.000718679919373244, 0.13657499849796295, 0.0052888281643390656, -0.12110656499862671, -0.02724318765103817, -0.00023562372371088713, -0.049809690564870834, -0.009152807295322418, 0.015069323591887951, -0.0319836251437664, 0.050675712525844574, 0.1597643345594406, 0.03666111081838608, 0.042722005397081375, 0.03503146395087242, -0.03479575365781784, 0.00016151955060195178, 0.08365557342767715, 0.03234424442052841, 4.643669672077522e-05, 1.1797913704217184e-32, -0.0398993045091629, 0.021725153550505638, -0.05618126690387726, 0.08679071068763733, 0.017218414694070816, 0.010244207456707954, 0.007083237636834383, 0.04254179075360298, -0.06719917804002762, -0.03510848060250282, -0.08817634731531143, 0.10628947615623474, -0.10381974279880524, 0.08907091617584229, 0.03891419619321823, -0.09649236500263214, -0.03974555432796478, 0.012577620334923267, 0.04408534988760948, -0.0069053880870342255, 0.0926303043961525, -0.018805542960762978, 0.04548991471529007, 0.0836787298321724, 0.08188760280609131, 0.03500529006123543, 0.09371046721935272, 0.015061959624290466, 0.04820272698998451, 0.04068237543106079, -0.10351689159870148, -0.0046181208454072475, -0.06309285759925842, 0.021929435431957245, -0.038399502635002136, -0.03421313688158989, -0.03715253248810768, -0.08691693842411041, -0.0753074511885643, 0.04922749847173691, -0.0857432410120964, 0.00905024353414774, -0.0954892486333847, -0.08127641677856445, 0.01996605098247528, -0.0020282419864088297, 0.026499368250370026, 0.05836489796638489, 0.04560922086238861, 0.0336533859372139, -0.02257797308266163, 0.023358335718512535, 0.04811733588576317, 0.04306340217590332, 0.010945508256554604, -0.02713663876056671, 0.008550765924155712, -0.05617784336209297, 0.03568816930055618, -0.01498517207801342, -0.017772875726222992, -0.02464381419122219, 0.002206110395491123, -0.0029405257664620876, 0.08530759066343307, 0.004204343073070049, 0.07248076051473618, -0.00017117874813266098, 0.011960109695792198, 0.05670179799199104, 0.03278178349137306, 0.053793150931596756, 0.001406224095262587, 0.007179193664342165, -0.03114464320242405, 0.02055211178958416, -0.10357879102230072, 0.03357068449258804, -0.04695887118577957, -0.010205757804214954, -0.04827229306101799, 0.015056685544550419, -0.026374420151114464, -0.005719746463000774, 0.04769632965326309, -0.04408733546733856, 0.026297494769096375, -0.05604421719908714, -0.01754320226609707, 0.03793901205062866, -0.024493874981999397, 0.036061279475688934, -0.06604979187250137, 0.08294865489006042, -0.03292351961135864, -9.98803223556297e-33, -0.06700106710195541, 0.013226932846009731, -0.05113248899579048, 0.11051969230175018, 0.003666664008051157, -0.04417392611503601, 0.043007463216781616, -0.018357863649725914, 0.10066946595907211, -0.019035449251532555, -0.08314666152000427, 0.009178019128739834, 0.02454512007534504, -0.031223366037011147, -0.02224631793797016, 0.009614639915525913, -0.0657133236527443, -0.007290733512490988, 0.025120459496974945, 0.03986893966794014, -0.018012193962931633, 0.07216791063547134, -0.12037058174610138, -0.011696902103722095, 0.012237725779414177, 0.03999248519539833, -0.09624713659286499, 0.0888797864317894, 0.017846891656517982, 0.017604943364858627, -0.011840428225696087, 0.012122220359742641, -0.016654781997203827, -0.018424147740006447, 0.002554346574470401, 0.03448748216032982, 0.032471053302288055, -0.008828943595290184, 0.00014921870024409145, -0.02452237345278263, 0.08088424801826477, -0.05742065981030464, -0.03377162665128708, -0.0483744740486145, 0.007740352768450975, 0.04681071266531944, -0.12520632147789001, -0.04988935962319374, -0.047449056059122086, 0.02805943414568901, 0.062478117644786835, 0.029162228107452393, 0.008813472464680672, -0.04466915875673294, -0.088286392390728, -0.024086788296699524, 0.10227429121732712, -0.02058298885822296, -0.08098380267620087, 0.05099393427371979, 0.02424817904829979, 2.9731350878137164e-05, 0.09662278741598129, 0.046920571476221085, 0.020810997113585472, -0.04720322787761688, 0.039486974477767944, 0.004329178482294083, -0.02136150933802128, -0.09735284745693207, 0.06558135896921158, -0.05089130625128746, 0.003207873785868287, 0.008338192477822304, 0.036861006170511246, 0.03605376556515694, 0.05049430578947067, -0.0991155281662941, -0.006855519488453865, -0.03718310967087746, -0.0459328256547451, -0.01462523452937603, 0.05952621251344681, 0.040456634014844894, -0.1067030280828476, 0.051075004041194916, -0.07661452889442444, 0.020450850948691368, 0.013004387728869915, 0.021762095391750336, -0.056342706084251404, 0.01917034573853016, -0.011681310832500458, 0.101569265127182, -0.023734554648399353, -6.332951585363844e-08, -0.043391529470682144, 0.008251218125224113, 0.04599906504154205, 0.03746441751718521, 0.037150509655475616, -0.06308089196681976, -0.05127688869833946, 0.09742551296949387, 0.03340795263648033, 0.023316798731684685, 0.0496644526720047, -0.03885985538363457, -0.06606988608837128, 0.06701238453388214, 0.06751682609319687, 0.021545924246311188, -0.009804713539779186, -0.006931978743523359, 0.009933631867170334, -0.026887476444244385, 0.06813530623912811, 0.028692634776234627, -0.03071068972349167, -0.06382011622190475, 0.03848087787628174, -0.07049528509378433, -0.06357022374868393, 0.09761630743741989, -0.04845903441309929, -0.01900583878159523, -0.01317038293927908, 0.002779423724859953, 0.06906002014875412, -0.0421726331114769, -0.03780824691057205, 0.02789652906358242, -0.04557458683848381, -0.09272809326648712, 0.012507476843893528, 0.02515559270977974, 0.029236381873488426, -0.0004052600997965783, -0.021820351481437683, -0.0784354954957962, -0.01165040209889412, -0.0508020780980587, -0.04410872235894203, -0.1288509964942932, 0.029340563341975212, 0.004456517286598682, -0.037678398191928864, 0.01221280638128519, 0.046429671347141266, 0.058447256684303284, 0.1105906292796135, -0.006186206359416246, 0.05740395188331604, -0.04636158421635628, 0.11437366902828217, 0.10032355040311813, 0.01964542455971241, 0.04593181982636452, 0.019961779937148094, -0.007519962731748819]}