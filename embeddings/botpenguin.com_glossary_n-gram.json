{"file_name": "botpenguin.com_glossary_n-gram", "text": "URL: https://botpenguin.com/glossary/n-gram\nWhat is N-Gram and How does it work?\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nWhat is N-Gram and How does it work?\nTable of Contents\nWhat is N-Gram?\nHow do N-Grams Work?\nApplications of N-Grams\nEvaluating N-Gram Models\nChallenges in Using N-Grams\nFrequently Asked Questions (FAQs)\nShare\nLink copied\nWhat is N-Gram?\nN-Gram is simply a sequence of N words, where N can be any positive integer.\nFor instance, a two-word sequence of words like\n\"please turn,\" \"turn your,\"\nor\n\"your homework\"\nis called a\n2-gram\n, and a three-word sequence of words like\n\"please turn your\"\nor\n\"turn your homework\"\nis called a\n3-gram\n. N-grams are the basic building blocks used in various NLP applications.\nWhat is an N-Gram Model in NLP?\nAn N-Gram model is a type of Language Model in NLP that focuses on finding the probability distribution over word sequences.\nThe model is built by counting the frequency of N-grams in corpus text and then estimating the probabilities of words in a sequence.\nFor instance, given the sentence\n\"The cat ate the white mouse.\"\n, what is the probability of\n\"ate the\"\nappearing in the sentence? An N-gram model calculates and provides such probabilities.\nHowever, a simple N-gram model has limitations, such as the sensitivity of training data and the occurrence of rare or unseen N-grams, among others.\nTo overcome these challenges, improvements are often made through the means of smoothing, interpolation, and back-off techniques.\nHow do N-Grams Work?\nN-Grams are constructed by consecutively breaking a given text down into chunks of\n'n'\nlength. If\n'n'\nis\n1\n,\neach word becomes a unigram. If\n'n'\nis\n2\n, adjacent pairs form bigrams, and so on.\nConsider this sentence:\n\"I like to play\"\n. In a bigram model, the sentence is divided as follows:\n[\"I like,\" \"like to,\" \"to play\"]\nN-Grams are pivotal in applications like\nspeech recognition\n, autocomplete functionality, and machine translation. They help imbue a sense of\n'context'\nto a sequence of words, allowing language-based prediction models to operate with enhanced accuracy.\nHow do N-Grams Work Operationally?\nCreating an N-Gram model revolves around four key steps:\nTokenization\n: The given text data is broken down into tokens (individual words).\nBuilding N-Grams\n: These tokens are then grouped together to form N-Grams of a specified length.\nCounting Frequencies\n: Next, the frequency of each N-Gram in the text is calculated for understanding the data's structure.\nApplication\n: Finally, these frequency distributions are leveraged for various NLP tasks, be it completing a sentence, suggesting next words, or even\ndetecting the language of the text\n.\nApplications of N-Grams\nN-grams are used in many NLP applications because of their ability to detect and leverage meaningful word sequences. Applications of N-grams include:\nAuto-Completion of Sentences\nN-grams are used for text prediction or auto-completion to suggest the next word in a sentence prediction.\nBy calculating the probability of a sequence of words appearing together, the N-gram model can predict what will most likely come next in the sentence.\nAuto Spell Check\nN-Grams are often used in spell-checking and correction in word processors, and search engines, among other applications.\nThe N-gram model can recommend a correction based on the probability of a misspelled word given its context to the previous N-1 words.\nDocument\nAnswer Your Customers like a Human\nUsing an AI Chatbot!\nTry BotPenguin\nSpeech Recognition\nN-Gram models are used in audio-to-text conversion to improve accuracy in speech recognition.\nIt can rectify speech-to-text conversion errors based on its knowledge of the probabilities and the context of previous words.\nMachine Translation\nSource: GeeksforGeeks\nN-gram models are employed in machine translation to produce more natural language in the target language.\nThe model predicts the next word given the previous N-1 words, translating the sentence step by step.\nGrammar Checking\nN-Gram models can also be used for grammar checking. The model detects if there is an error of omission, e.g., a missing auxiliary verb, and suggests probable corrections that match the preceding context.\nN-Gram Models in Machine Translation\nN-gram models are widely used in machine translation to translate text from the source language to a target language.\nThe models predict the next word given the previous N-1 words, translating the sentence step by step.\nBy modeling long-range dependencies, such as tense, word order, and sentence structure, N-gram models can help overcome some of the limitations of traditional rule-based translation systems, delivering better translation quality.\nN-Grams for Spelling Error Correction\nN-Gram models can help in correcting misspelled words. By calculating the probability of each word based on its context and frequency of occurrence in the corpus, the model can suggest a correction for a misspelled word.\nOften, dictionary lookups fail as words that are spelled similarly may have different meanings.\nN-Grams at Different Levels\nN-grams can be used not only at the word level but also at the character level, forming sequences of n characters (n-grams).\nCharacter level N-grams are useful for word completion, auto-suggestion, typo correction, and root-word separation.\nN-Grams for Language Classification and Spelling\nN-Gram statistics can be used in many ways to classify languages or differentiate between US and UK spellings. Language classification is useful in chatbots, where the bot adapts to the user's preferred language.\nIn spellings, the N-gram model can differentiate between different spellings of the same word in British English and American English.\nEvaluating N-Gram Models\nN-gram models can be evaluated through intrinsic or extrinsic assessment methods. Intrinsic evaluation involves conducting a test that measures the performance of the model based on its strengths and weaknesses.\nExtrinsic evaluation is an end-to-end method that involves the integration of N-gram models into an application and evaluating the performance of the app.\nPerplexity as a Metric for N-Gram Models\nPerplexity is a popular evaluation metric for N-gram models that measures how accurately the model predicts future words.\nLower perplexity values indicate that the N-gram model performed better in predicting the next word.\nChallenges in Using N-Grams\nSensitivity to the Training Corpus\nN-Gram models' performance is significantly dependent on the training corpus, meaning that the probabilities often encode particular facts about a given training corpus.\nAs a result, the performance of the N-gram model varies with the N-value and the data it was trained on.\nSmoothing and Sparse Data\nSparse data is a common challenge in N-Gram models. Any N-gram that appeared a sufficient number of times might have a reasonable estimate for its probability.\nDue to data limitations, some perfectly acceptable word sequences are bound to be missing from it. Smoothing is the primary technique that addresses spelled-out zeros in the N-gram matrix.\nSo there you have it - a comprehensive glossary page that covers everything you need to know about N-grams.\nUse N-grams with caution, be mindful of the challenges and limitations and, most importantly, have fun creating intelligent chatbots, spam filters, auto-corrects and more with N-grams!\nDocument\nMake Your Own AI Chatbot\nWithout Any Coding!\nGet Started FREE\nFrequently Asked Questions (FAQs)\nHow are N-grams commonly used in text prediction?\nN-grams are used in text prediction by analyzing the frequency of occurrence of N-grams in a given dataset.\nThis information is then utilized to predict the most likely next word or sequence of words based on the context.\nCan N-grams handle different languages?\nYes, N-grams can be used with any language as they rely on the statistical analysis of sequences of words or characters.\nHowever, the effectiveness of N-grams may vary depending on the complexity and structure of the language being analyzed.\nWhat challenges can arise when using N-grams?\nSome challenges when using N-grams include the exponential growth in the number of possible N-grams as the value of N increases, the sparsity of certain N-grams in the dataset, and the limitation in capturing long-range dependencies in language.\nHow can N-grams be used in spam detection?\nN-grams can be helpful in spam detection by analyzing the frequency of occurrence of specific N-grams or patterns associated with spam messages.\nThis information can be used to identify and filter out potential spam emails or messages.\nAre there any limitations to using N-grams?\nYes, N-grams have limitations. They may struggle with capturing semantics and context in\nnatural language\n, especially for tasks like sentiment analysis.\nAdditionally, N-grams can be memory-intensive, and the choice of N value can significantly impact performance and accuracy.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat is N-Gram?\nHow do N-Grams Work?\nApplications of N-Grams\nEvaluating N-Gram Models\nChallenges in Using N-Grams\nFrequently Asked Questions (FAQs)\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.12052692472934723, -0.08030864596366882, 0.01787479966878891, -0.004711548797786236, -0.04364629462361336, -0.035488151013851166, 0.05518456548452377, 0.07825468480587006, 0.00315054040402174, 0.016978783532977104, 0.04981622099876404, -0.010364962741732597, 0.008299938403069973, 0.016445862129330635, 0.10019931197166443, -0.012712780386209488, 0.11285677552223206, -0.09554754197597504, -0.10089269280433655, -0.034441035240888596, 0.016495028510689735, -0.012425830587744713, 0.039889950305223465, -0.03334161639213562, -0.03392462432384491, -0.02848118171095848, -0.04569392651319504, -0.027072548866271973, 0.0002493122301530093, -0.06457432359457016, -0.0033201430924236774, 0.028568308800458908, 0.008519588969647884, 0.0562758594751358, -0.02106032893061638, -0.04655950143933296, -0.02895999327301979, 0.017853712663054466, 0.08910425007343292, -0.05158154293894768, -0.07481995224952698, -0.09796248376369476, -0.07088745385408401, 0.005346526857465506, 0.10146458446979523, 0.009464495815336704, -0.065238818526268, 0.04363752529025078, 0.004972151014953852, 0.07753245532512665, -0.09782088547945023, -0.05559464916586876, 0.038749199360609055, 0.06715335696935654, -0.031495701521635056, 0.0313357375562191, -0.035440221428871155, 0.018067317083477974, 0.0456574484705925, -0.0026865529362112284, -0.06229628250002861, -0.00035711441887542605, 0.03904810920357704, 0.04470130056142807, -0.00807817094027996, 0.021630527451634407, -0.11207978427410126, -0.0022879892494529486, -0.009275417774915695, -0.03288527950644493, -0.021882973611354828, -0.011401389725506306, -0.030641254037618637, 0.07897276431322098, -0.0076910885982215405, -0.033211980015039444, 0.0013875432778149843, 0.007023590616881847, 0.025568537414073944, -0.0688057467341423, 0.0024667440447956324, 0.061656415462493896, 0.01262179110199213, 0.06902315467596054, -0.03159746900200844, -0.04561734199523926, 0.002068439032882452, 0.056483712047338486, -0.006926620379090309, 0.016211073845624924, 0.032647598534822464, -0.0020554536022245884, 0.030165622010827065, 0.01893223449587822, 0.018678614869713783, 0.022015703842043877, -0.0742829293012619, 0.04504065588116646, -0.04684971645474434, -0.006970092188566923, 0.015196183696389198, -0.025289742276072502, -0.039716433733701706, -0.09525600075721741, -0.06322348862886429, 0.009778779000043869, 0.055570486932992935, -0.013320817612111568, 0.15664935111999512, 0.007746616378426552, -0.13630470633506775, -0.05130603536963463, -0.01247513946145773, -0.027051694691181183, -0.01033945195376873, 0.015905098989605904, -0.035424958914518356, 0.05974440276622772, 0.1581815630197525, 0.013100399635732174, 0.04342291131615639, 0.06234556809067726, -0.0030376059003174305, -0.010346738621592522, 0.03876790776848793, 0.04596296697854996, 0.014110136777162552, 1.0093431467161512e-32, -0.03831738606095314, 0.03556283563375473, -0.07135847210884094, 0.08993533998727798, 0.013486362993717194, 0.011072752065956593, -0.002751588588580489, 0.04224039986729622, -0.06308187544345856, -0.03452656418085098, -0.08139947801828384, 0.09977400302886963, -0.07189536839723587, 0.03248129412531853, 0.030125517398118973, -0.06224110722541809, -0.009181668050587177, 0.025372635573148727, 0.054265860468149185, 0.011713532730937004, 0.08930493891239166, -0.013120596297085285, 0.05712046101689339, 0.07037118077278137, 0.11554441601037979, 0.02602335810661316, 0.05717258155345917, 0.009847226552665234, 0.05835365131497383, 0.035383228212594986, -0.08074028044939041, -0.010044875554740429, -0.061984237283468246, 0.014935898594558239, -0.04189587011933327, -0.06389652192592621, -0.03762184828519821, -0.12189499288797379, -0.06536956876516342, 0.017102759331464767, -0.14349982142448425, 0.02283519133925438, -0.0952175036072731, -0.05787716060876846, 0.012442543171346188, 0.028713354840874672, 0.00420866534113884, 0.025528451427817345, 0.03424006327986717, 0.04150564223527908, -0.01668185368180275, 0.025289487093687057, 0.03473600372672081, 0.053059451282024384, 0.006698985584080219, -0.011740264482796192, 0.02801615186035633, -0.041571371257305145, -0.005680781789124012, -0.030141204595565796, -0.010859762318432331, -0.02254602685570717, -0.000942723941989243, -0.023447738960385323, 0.0570792630314827, 0.021215882152318954, 0.04171280190348625, 0.034120287746191025, 0.034732479602098465, 0.02725057303905487, 0.04440351203083992, 0.03568130359053612, -0.02441294491291046, 0.047694072127342224, -0.03417567163705826, 0.015831129625439644, -0.07942433655261993, 0.022685842588543892, -0.06121378764510155, 0.0001330096274614334, -0.026530463248491287, -0.006302947644144297, -0.020558545365929604, -0.04876674339175224, 0.05207538604736328, -0.018941573798656464, 0.02818823605775833, -0.041992198675870895, -0.009883888065814972, 0.017902150750160217, -0.027004897594451904, 0.06248755753040314, -0.08986548334360123, 0.07966272532939911, -0.03997553884983063, -8.081009383124742e-33, -0.04209618270397186, 0.016575096175074577, -0.06098893657326698, 0.09831182658672333, -0.005995720624923706, -0.03384658321738243, 0.025053231045603752, -0.032086215913295746, 0.11016074568033218, -0.004369964357465506, -0.09779771417379379, -0.02362070605158806, 0.026824377477169037, -0.027848541736602783, 0.002349013928323984, 0.018143875524401665, -0.050404053181409836, -0.02611355111002922, 0.00989274587482214, 0.020068008452653885, -0.026568597182631493, 0.05559321492910385, -0.1319589763879776, 0.014461679384112358, -0.012442534789443016, 0.048516131937503815, -0.08089202642440796, 0.06390995532274246, 0.019495908170938492, 0.0203389972448349, -0.003809710731729865, -0.012689760886132717, -0.030589168891310692, 0.000246174429776147, 0.00838394183665514, 0.04533175379037857, 0.035851456224918365, -0.014807994477450848, -0.015709232538938522, -0.05983513593673706, 0.10647846758365631, -0.038789115846157074, -0.03586014360189438, -0.07686559110879898, -0.03584631159901619, 0.039552994072437286, -0.1419524997472763, -0.026535816490650177, -0.056782159954309464, 0.03645571693778038, 0.06256798654794693, 0.007248335983604193, 0.03244467079639435, -0.04881548881530762, -0.09892158955335617, -0.034656647592782974, 0.09398843348026276, -0.0018057121196761727, -0.10775905847549438, 0.009950779378414154, 0.02893105335533619, 0.011870352551341057, 0.07297812402248383, 0.07146649062633514, 0.03284284472465515, -0.03791441768407822, 0.05098720267415047, 0.027257712557911873, -0.000255331106018275, -0.10218847543001175, 0.03502986580133438, -0.05213800445199013, -0.011233987286686897, 0.0010263839503750205, 0.01626734621822834, 0.08292704820632935, 0.04967626556754112, -0.13006454706192017, 0.004887046758085489, -0.03510081395506859, -0.04460391029715538, 0.011989022605121136, 0.06854753196239471, 0.034587349742650986, -0.07573098689317703, 0.07584737986326218, -0.02329845167696476, 0.020605411380529404, -0.0016422353219240904, 0.020970549434423447, -0.028206422924995422, 0.02573227696120739, -0.03029196709394455, 0.10835559666156769, -0.0009208492701873183, -5.885848608500055e-08, -0.0362788587808609, 0.006504801567643881, 0.044989656656980515, 0.04867957904934883, 0.03538993373513222, -0.06944789737462997, -0.04750563204288483, 0.07608362287282944, 0.02936626970767975, 0.032696425914764404, 0.023426633328199387, -0.017835747450590134, -0.07567261159420013, 0.06582843512296677, 0.05051015689969063, 0.0009856314864009619, -0.008131977170705795, -0.02075592242181301, 0.0025563775561749935, -0.032384321093559265, 0.07151378691196442, 0.020398227497935295, -0.02947305142879486, -0.017261628061532974, 0.03222517669200897, -0.05877190828323364, -0.04875308275222778, 0.0792497918009758, -0.025311043485999107, -0.030062178149819374, -0.026665613055229187, -0.020409928634762764, 0.048530273139476776, -0.043023452162742615, -0.004073248710483313, 0.002334622433409095, -0.06060678884387016, -0.08892188221216202, 0.010891891084611416, 0.0426434762775898, 0.026667369529604912, 0.016399141401052475, 0.012450928799808025, -0.08448448032140732, -0.020436882972717285, -0.04398123919963837, -0.06772462278604507, -0.10293109714984894, 0.03741155192255974, 0.005072395782917738, -0.06321083754301071, -0.000336762546794489, 0.05104861408472061, 0.041988275945186615, 0.07949427515268326, -0.02836516872048378, 0.04536619037389755, -0.003914504311978817, 0.09578517824411392, 0.10259667038917542, 0.03556957095861435, 0.022744061425328255, 0.03320048749446869, 0.024491649121046066]}