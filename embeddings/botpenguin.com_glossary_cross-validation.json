{"file_name": "botpenguin.com_glossary_cross-validation", "text": "URL: https://botpenguin.com/glossary/cross-validation\nCross-Validation: Types and Limitations | BotPenguin\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nCross-Validation\nTable of Contents\nWhat is Cross-Validation?\nWhy is Cross-Validation Used?\nTypes of Cross-Validation\nHow Does Cross-Validation Work?\nWhere do we Implement Cross-Validation?\nLimitations and Challenges of Cross-Validation\nFrequently Asked Questions\nShare\nLink copied\nWhat is Cross-Validation?\nCross-validation is a technique used in machine learning to evaluate the performance of a model. It provides a better estimate of how well the model will generalize to unseen data by splitting the data into multiple subsets. It helps in assessing the model's ability to handle different scenarios and identify potential issues such as overfitting or underfitting.\nCross-validation plays a crucial role in assessing the performance and reliability of machine learning models. It provides a more accurate evaluation of the model's performance by using multiple partitions of the data. This helps in making informed decisions about model selection, hyperparameter tuning, and assessing the robustness of the chosen model.\nWhy is Cross-Validation Used?\nCross-validation is a widely used technique in machine learning and statistical analysis to evaluate the performance of a model. Let's explore its significance.\nModel Performance Evaluation\nOne of the main reasons cross-validation is used is to accurately evaluate the performance of a model on unseen data, helping to choose the best model for a specific problem.\nPreventing Overfitting\nCross-validation helps identify overfitting, which occurs when a model performs well on training data but poorly on new, unseen data, ensuring a more robust model.\nModel Selection and Hyperparameter Tuning\nCross-validation allows us to compare different models or\nalgorithms\nand fine-tune their hyperparameters, enabling the selection of the most optimal model for a problem.\nMore Reliable Estimates\nBy splitting data into different folds and training/testing on various subsets, cross-validation helps in obtaining more reliable estimates of a model's performance.\nData Efficiency\nIn situations with limited data, cross-validation can maximize the usage of available data for training and testing, increasing overall data efficiency and model reliability.\nTypes of Cross-Validation\nK-Fold Cross-Validation\nK-Fold Cross-Validation is a commonly used technique where the data is divided into 'K' equal-sized folds or partitions. The model is trained on K-1 folds and evaluated on the remaining fold. This process is repeated K times, with each fold serving as the test set once. The performance metric is then averaged across all iterations.\nStratified K-Fold Cross-Validation\nStratified K-Fold Cross-Validation is an extension of K-Fold Cross-Validation that ensures the distribution of class labels is preserved in each fold. This technique is especially useful for imbalanced datasets, where the number of samples in each class differs significantly.\nLeave-One-Out Cross-Validation (LOOCV)\nLeave-One-Out Cross-Validation is a special case of K-Fold Cross-Validation where K is equal to the number of samples in the dataset. In each iteration, one sample is used for testing, and the rest are used for training. LOOCV provides the least biased estimate of model performance but can be computationally expensive.\nShuffle-Split Cross-Validation\nShuffle-Split Cross-Validation involves randomly shuffling the dataset and splitting it into training and test sets multiple times. This technique allows for more control over the training and testing proportions and can be useful for large datasets.\nTime Series Cross-Validation\nTime Series Cross-Validation is specifically designed for time series data. It ensures that the model is evaluated on data that occurs after the training data to simulate real-world scenarios.\nHow Does Cross-Validation Work?\nEver wondered how cross-validation works in machine learning model evaluation? Let's walk through its intriguing process:\nDivision of the Dataset\nThe initial step in cross-validation involves dividing your\ndataset\ninto a certain number of 'folds', or subsets. The most common method is k-fold cross-validation, where 'k' is typically set to 5 or 10.\nTraining and Validation\nEach fold takes turns serving as the validation set, while the remaining folds make up the training set. The model is trained on the training set and then validated on the\nvalidation set\n, producing a measure of model performance.\nRepeating the Process\nThis process of training and validation is repeated k times, each time with a different fold serving as the\nvalidation set\n. This repetition ensures all data has a chance to be included in the training and validation sets, providing a comprehensive assessment of the model's performance.\nAggregating Results\nAfter the model has been trained and validated k times, the results from the k iterations are aggregated. This typically involves calculating the average of the performance measure across all k iterations to give a single, averaged measure of model performance.\nFine-Tuning the Model\nThe results of cross-validation can be used to fine-tune a\nmachine learning\nmodel. By comparing the model's performance across different configurations of hyperparameters during the cross-validation process, the model can be optimized for its task.\nWhere do we Implement Cross-Validation?\nPredictive Model Validation\nCross-validation is often implemented in predictive model validation. By splitting the dataset into training and validation sets multiple times, you can test how the model performs on unseen data, which can help you avoid overfitting.\nHyperparameter Tuning\nWhen tuning a model's hyperparameters, cross-validation can be used to estimate their effectiveness. This ensures the parameters selected do not merely perform well on one specific subset of the data.\nComparing Different Models\nTo compare the predictive abilities of different modeling approaches under the same conditions, cross-validation can be implemented. It measures the models\u2019 performance on various data subsets, fostering a more reliable comparison.\nFeature Selection\nIn determining which features contribute most to the predictive capability of a model, one can use cross-validation. By analyzing how the model performs without certain features, you can identify the important ones.\nAssessment of Model Robustness\nCross-validation is used to test model robustness, ensuring that the model has not just memorized the training data, but can generalize well to new, unseen data. This is vital to assert the model's ability to make accurate predictions when deployed.\nLimitations and Challenges of Cross-Validation\nCross-validation is a widely used technique for model evaluation and selection. However, it\u2019s not without its limitations and challenges. Let's dive into some of these:\nComputational Complexity\nPerforming cross-validation can be computationally expensive, particularly when dealing with large datasets or complex models. Repeatedly training and testing the model over multiple folds increases the time and resource requirements, which can be a stumbling block in time-sensitive projects.\nChoice of k-folds\nSelecting an appropriate number of folds (k) can be challenging, as a balance needs to be struck between accuracy and efficiency. A larger k value will yield more accurate results but comes at the cost of higher computational complexity. Conversely, a smaller k value might be more efficient but may not provide sufficiently accurate results.\nVariation in Results\nCross-validation results can vary depending on how the data is divided into folds. When partitions lead to an uneven representation of classes or patterns, model performance may suffer, creating misleading or inconsistent results. Strategies like stratified k-fold cross-validation can help mitigate this issue but may not entirely eliminate it.\nData Leakage\nCross-validation can be susceptible to data leakage if careful attention is not paid to data preprocessing steps. Data leakage occurs when information from the testing set is incorporated into the training set, leading to overly optimistic performance estimates. To prevent leakage, preprocessing should be performed separately within each split of the data.\nHandling Imbalanced Data\nIn the presence of imbalanced class distributions, cross-validation can produce biased results. The minority class samples might not be well-represented in each fold, making it difficult for the model to learn patterns associated with that class. To address this challenge, techniques like oversampling, undersampling, and cost-sensitive learning can be employed when performing cross-validation.\nFrequently Asked Questions\nWhat is cross-validation and why is it important?\nCross-validation is a technique to evaluate machine learning models. It splits data into subsets for more reliable evaluation and helps in selecting the best model and avoiding overfitting.\nWhat are the different types of cross-validation techniques?\nThere are several types, including k-fold, stratified k-fold, leave-one-out, shuffle-split, and time series cross-validation. Each has its own use case and benefits.\nHow does cross-validation work?\nIt involves splitting data into training and test sets, training the model on the training set, and evaluating its performance on the test set. The process is repeated for each fold or partition.\nWhat are the main advantages of using cross-validation?\nCross-validation provides a better estimate of model performance, allows for model comparison, enables hyperparameter tuning, and helps identify overfitting or underfitting issues.\nWhat are some limitations of cross-validation?\nCross-validation can still suffer from overfitting or underfitting issues, may not accurately assess the performance of imbalanced datasets, and can be computationally expensive, especially with leave-one-out cross-validation. Nested cross-validation can help mitigate some limitations.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat is Cross-Validation?\nWhy is Cross-Validation Used?\nTypes of Cross-Validation\nHow Does Cross-Validation Work?\nWhere do we Implement Cross-Validation?\nLimitations and Challenges of Cross-Validation\nFrequently Asked Questions\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.11653164774179459, -0.08161862939596176, 0.02109256573021412, -0.012722965329885483, 0.004629841540008783, -0.04356835409998894, 0.0352514423429966, 0.060741301625967026, -0.010809001512825489, 0.005323906894773245, 0.0457049161195755, -0.04446664825081825, 0.015951083973050117, 0.032808657735586166, 0.10079609602689743, -0.001397149171680212, 0.10711582005023956, -0.075874462723732, -0.082951620221138, -0.013251593336462975, -0.009568998590111732, -0.04030752554535866, 0.02840912528336048, -0.020386364310979843, -0.043754514306783676, -0.0495634600520134, -0.05385993421077728, 0.0015893456293269992, -0.01799539104104042, -0.09374111145734787, 0.011796568520367146, 0.020780250430107117, -0.03760184347629547, 0.05164119601249695, 0.014148568734526634, -0.04732217639684677, -0.02518153004348278, 0.037440571933984756, 0.08557415753602982, -0.040056366473436356, -0.08164351433515549, -0.10514670610427856, -0.04493877664208412, -0.0002687757078092545, 0.08267837017774582, 0.00029589715995825827, -0.06919637322425842, 0.00245835492387414, 0.007892545312643051, 0.08694567531347275, -0.08464723080396652, -0.04472754895687103, 0.041519712656736374, 0.05593252554535866, -0.04253719002008438, 0.034049537032842636, -0.030452461913228035, 0.010884077288210392, 0.03354649990797043, -0.006115395575761795, -0.03920145705342293, -0.01163322664797306, 0.038590025156736374, 0.04407479614019394, -0.037461478263139725, 0.05106271058320999, -0.13458098471164703, -0.017339153215289116, -0.018638690933585167, -0.020647011697292328, -0.018331849947571754, -0.013204689137637615, -0.057576850056648254, 0.07358816266059875, 0.011563493870198727, -0.0219725351780653, 0.011579077690839767, -0.022378945723176003, 0.025959590449929237, -0.07158862054347992, -0.028284952044487, 0.08063861727714539, -0.008536238223314285, 0.053035635501146317, 0.004198005422949791, -0.011573870666325092, -0.022017350420355797, 0.04715090990066528, -0.024209804832935333, 0.008167785592377186, 0.0722011849284172, -0.011966973543167114, 0.045391861349344254, 0.03640252351760864, 0.022142319008708, 0.016104577109217644, -0.0700167566537857, 0.02350323647260666, -0.047575607895851135, 0.0033557559363543987, -0.014841603115200996, -0.043895334005355835, -0.05354110524058342, -0.07345268130302429, 0.0015520290471613407, 0.006720723118633032, 0.06664668023586273, -0.04426555708050728, 0.14188382029533386, 0.011708536185324192, -0.10815583914518356, -0.04085082933306694, -0.002376088872551918, -0.01765679568052292, -0.00027040770510211587, 0.044626351445913315, -0.03978893160820007, 0.07252148538827896, 0.13801753520965576, 0.027039870619773865, 0.038173556327819824, 0.051253482699394226, 0.0478060245513916, -0.019092164933681488, 0.0683847963809967, 0.016643095761537552, 0.0149418069049716, 1.1385520898589955e-32, -0.04125039279460907, 0.03488290309906006, -0.06401892751455307, 0.08731400966644287, 0.004131777212023735, 0.030476843938231468, 0.0005720183835364878, 0.032705921679735184, -0.07891786843538284, -0.028747353702783585, -0.10892537236213684, 0.09470207989215851, -0.0851370096206665, 0.02451746165752411, 0.053072668612003326, -0.058405984193086624, -0.022441735491156578, 0.02537674643099308, 0.031546734273433685, 0.0076078507117927074, 0.09993591904640198, -0.06015516445040703, 0.05665004253387451, 0.08974681794643402, 0.09577586501836777, 0.036988239735364914, 0.06732770800590515, 0.02111833728849888, 0.059306271374225616, 0.03945722430944443, -0.0930277481675148, -0.014869088307023048, -0.0322839692234993, 0.022728366777300835, -0.021026240661740303, -0.012265718542039394, -0.048053059726953506, -0.1152491569519043, -0.05864603817462921, 0.06328719109296799, -0.1371125429868698, -0.0003192756848875433, -0.08472711592912674, -0.05426386371254921, 0.048032496124506, -0.019232116639614105, 0.030695142224431038, 0.019135741516947746, 0.015606176108121872, 0.03378735110163689, -0.053533319383859634, 0.025609983131289482, 0.02210915833711624, 0.04138990864157677, -0.023764045909047127, -0.031939152628183365, 0.032579634338617325, -0.019008418545126915, 0.012664560228586197, -0.019505076110363007, 0.0063459728844463825, -0.037493497133255005, -0.04243963584303856, -0.0204804427921772, 0.04322132468223572, 0.014869099482893944, 0.04085417836904526, 0.0018156477017328143, 0.02444545552134514, 0.015498718246817589, 0.02484416961669922, 0.034020163118839264, -0.03557205945253372, 0.04460584372282028, -0.03229604661464691, -0.021623840555548668, -0.1016266867518425, 0.06722184270620346, -0.030936311930418015, -0.024127941578626633, -0.03401889279484749, 0.0068138777278363705, -0.042490627616643906, -0.01682436466217041, 0.07663410156965256, -0.051930904388427734, 0.0248420387506485, -0.045948389917612076, -0.04193253442645073, 0.05408956855535507, -0.038600996136665344, 0.07518785446882248, -0.057067323476076126, 0.058013591915369034, -0.045203473418951035, -8.859788349539923e-33, -0.05070266127586365, 0.016534406691789627, -0.029555650427937508, 0.1062329038977623, 0.008554087020456791, -0.050146546214818954, 0.0510333888232708, -0.037986043840646744, 0.08238384872674942, 0.007115836255252361, -0.08919311314821243, -0.022333206608891487, 0.024780502542853355, -0.04218112304806709, -0.022453326731920242, 0.011012248694896698, -0.08050147444009781, -0.016662513837218285, 0.030690092593431473, -0.0009266422712244093, 0.01728358305990696, 0.06525775790214539, -0.10710054636001587, 0.03863232582807541, -0.03185585141181946, 0.05300521478056908, -0.07275782525539398, 0.0302216075360775, 0.03282260522246361, 0.026322554796934128, -0.012756709940731525, 0.017916275188326836, -0.025494394823908806, 0.01581396907567978, 0.019430268555879593, 0.042190443724393845, 0.03088664636015892, -0.010996997356414795, -0.006747940555214882, -0.018567590042948723, 0.0936870276927948, -0.04323720559477806, -0.06215659901499748, -0.0927732065320015, -0.023852674290537834, 0.04084979370236397, -0.15671280026435852, -0.038866255432367325, -0.05219592899084091, 0.020387616008520126, 0.052338212728500366, -0.0033511079382151365, 0.03274991363286972, -0.02943124808371067, -0.08026301115751266, -0.03611566871404648, 0.08884924650192261, 0.012883558869361877, -0.0876825675368309, 0.030728386715054512, 0.044026803225278854, 0.009782304055988789, 0.0617644339799881, 0.08530952781438828, 0.06306050717830658, 0.011600029654800892, 0.05042561516165733, 0.030223671346902847, 0.0031740781851112843, -0.08088269829750061, 0.04419178515672684, -0.048035070300102234, -0.008381116203963757, -0.02683042176067829, 0.017622085288167, 0.067897267639637, 0.04619484022259712, -0.10870111733675003, 0.025208180770277977, -0.039091676473617554, -0.06716864556074142, -0.012257315218448639, 0.08424851298332214, 0.06270100921392441, -0.08768058568239212, 0.08098628371953964, -0.022882157936692238, 0.010898594744503498, -0.02635296620428562, 0.01067985687404871, -0.047300372272729874, 0.026535049080848694, -0.011986680328845978, 0.07804398983716965, -0.014577102847397327, -6.018714771016676e-08, -0.023495519533753395, -0.0028583870735019445, 0.054612547159194946, 0.0444401353597641, 0.03436056897044182, -0.05998195335268974, -0.04336153715848923, 0.017013367265462875, 0.026609838008880615, 0.029300982132554054, 0.029254578053951263, -0.0367375984787941, -0.05237654596567154, 0.061556220054626465, 0.0743042379617691, -0.021516211330890656, -0.03319226950407028, 0.008566607721149921, 0.00092941930051893, -0.006769985426217318, 0.07410810142755508, 0.0305198822170496, -0.03330184146761894, -0.02673318237066269, 0.033992428332567215, -0.060023944824934006, -0.0746520608663559, 0.11278873682022095, -0.041292864829301834, -0.011370827443897724, -0.012200566940009594, -0.040284883230924606, 0.06088413670659065, -0.043960582464933395, -0.0034583089873194695, 0.01588522084057331, -0.07385925203561783, -0.0664377436041832, 0.029946092516183853, 0.06344985961914062, 0.013831526972353458, 0.023303618654608727, -0.0029010057915002108, -0.08558429032564163, -0.0012101478641852736, -0.0478070043027401, -0.07655394077301025, -0.12252631038427353, 0.018453236669301987, -0.011006567627191544, -0.056469302624464035, -0.004837991204112768, 0.058674994856119156, 0.0576971061527729, 0.07017765939235687, -0.00794346071779728, 0.05328233540058136, -0.008455733768641949, 0.09672816842794418, 0.09021247923374176, 0.05086812004446983, 0.010184141807258129, 0.061430685222148895, 0.02856137789785862]}