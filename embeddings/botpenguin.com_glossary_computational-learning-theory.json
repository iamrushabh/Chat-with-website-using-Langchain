{"file_name": "botpenguin.com_glossary_computational-learning-theory", "text": "URL: https://botpenguin.com/glossary/computational-learning-theory\nWhat is Computational Learning Theory & its role| BotPenguin\nWhy BotPenguin\nProduct\nSolutions\nPricing\nPartners\nResources\nLogin\nGet Started FREE\nIntegrations\nExperience 80+ world-class integrations.\nKey Features\nTake your business to the next level with our awesome key features.\nLive Chat\nStay in the loop with your clientele 24*7!\nUnified Inbox\nServe your customers across all platforms.\nAnalytics\nSpeedtrack your growth with our top-of-the-line analytics tools!\nMobile App\nMake, monitor, & manage your AI chatbots with our mobile app.\nCHATBOT COMPARISONS\nBotPenguin vs. Manychat\nBotPenguin vs. Tidio\nBotPenguin vs. Tawk.to\nBotPenguin vs. Wati\nBotPenguin vs. Interakt\nBotPenguin vs. AiSensy\nBotPenguin vs. Landbot\nWHAT CAN IT DO?\nMarketing Automation\nMake marketing a boon from the automation gods!\nFB Automation\nEngage with your customers on a deeper level.\nWhatsApp Automation\nGet that nifty automation for WhatsApp too!\nAppointment Bookings\nNo more delays, BotPenguin\u2019s got you here!\nCustomer Support\nYour customers are in for a treat with this automation.\nLead Generation\nGain more lead without any extra effort or expenses\nWHO CAN USE IT?\nHealthcare\nGive your patients world-class healthcare service!\nEducation\nMake admissions and automate processes in a jiffy!\nE-commerce\nCreate the best E-commerce service with ease!\nReal Estate\nMake Real Estate great again with BotPenguin!\nConsultants\nBoost up with our one-stop marketing solution!\nSaaS\nTake your SAAS game to the next level with BotPenguin!\nTours & Travels\nProvide extraordinary tour and travel services with BotPenguin!\nInsurance\nLaunch AI-driven Insurance Bot to Promote, Sell, & Manage Policies.\nWHERE CAN IT RUN?\nInstagram Chatbot\nAttract leads, boost sales, and chat 24/7 with Instagram Chatbots.\nWhatsApp Chatbot\nStart conversing like a real person with BotPenguin!\nTelegram Chatbot\nCutting-edge features for you to grow your business on Telegram.\nFacebook Chatbot\nDo everything at once with BotPenguin on Facebook.\nWebsites Chatbot\nBotPenguin grows your website and keeps your customers engaged.\nWordpress Chatbot\nBotPenguin thrives on WordPress and makes it awesome.\nMicrosoft Teams Chatbot\nMaximize your teams productivity with MS Teams Bot.\nShopify Chatbot\nBoost your Shopify Business With BotPenguin\u2019s AI-powered chatbot.\nWooCommerce Chatbot\nSell effortlessly on your WooCommerce store with BotPenguin.\nSquarespace Chatbot\nGet the most out of Squarespace with BotPenguin\nCUSTOM DEVELOPMENT\nWhitelabel ChatGPT\nApply your branding on ChatGPT, Launch your own AI platform\nChatGPT Custom Plugins\nIntegrate your service straight into ChatGPT\nCustom Chatbot Development\nBuild enterprise-grade chatbots with the best\nChatGPT Clone\nAdd functionality and branding on ChatGPT\nHIRE DEVELOPERS\nChatbot Developers\nBuild Lighter, Faster, Smarter-Efficiently\nChatGPT Developers\nRide the GPT wave with trained surfers\nChatGPT Consultants\nAdvice that makes the difference in your AI journey\nPARTNER PROGRAMS\nPartners Home\nJoin hands with us, and welcome growth\nWhatsApp Whitelabel Partners\nConquer the WhatsApp land with BotPenguin\u2019s White Label Platform\nWhitelabel Partners\nSay hi to the best Whitelabel chatbot platform ever\nAffiliate Partners\nEarn more and keep your clients happier\nImplementation Partners\nAs they say, a partner is worth trillions!\nPARTNER PRICING\nWhitelabel Chatbot Pricing\nOur pricing for Whitelabel Chatbot\nImplementation Partnership Pricing\nOur pricing for Implementation Partnership\nOUR RESOURCES\nBlogs\nRead the latest blogs on chatbots, AI, automations & more\nVideos\nWatch tutorials, webinars, and demos to master our chatbots.\nCase Study\nRead how BotPenguin transformed business communication\nE-book\nExplore e-books written by experts for all your business needs!\nHelp Docs\nFind detailed guides and tips for all your chatbot needs.\nNewsroom\nExplore how BotPenguin is making headlines in the chatbot industry.\nCommunity Support\nJoin our vibrant community to unlock exclusive content & expert guidance\nLATEST BLOG\nWhy is BotPenguin the best platform to develop a chatbot?\nIntroducing ChatGPT 4o for BotPenguin\nCreate your first AI Chatbot\nGet Started FREE\nGLOSSARY\nComputational Learning Theory\nTable of Contents\nWhat is Computational Learning Theory?\nWhy Computational Learning Theory?\nHow does Computational Learning Theory work?\nWhen is Computational Learning Theory Applied?\nChallenges in Operationalizing Computational Learning Theory\nBest Practices For Computational Learning Theory (CoLT)\nFrequently Asked Questions (FAQs)\nShare\nLink copied\nWhat is Computational Learning Theory?\nComputational Learning Theory (CoLT) is a subfield of Artificial Intelligence that works on developing and analyzing algorithms that can learn from and make predictions based on data.\nThis alluring scientific field borrows from game theory, information theory, probability theory, and complexity theory to illuminate our comprehension of machine learning in a concrete and quantifiable way.\nWhy Computational Learning Theory?\nLet's begin with a\nmachine learning model's primary objective:\nTo make accurate predictions.\nBut it can be a cryptic task to determine just how much data is sufficient to ensure these predictions' accuracy. That\u2019s where computational learning theory shines.\nThe field enables us to scrutinize the machinations behind\nmachine learning algorithms\n, quantifying the required data volume to improve a model\u2019s performance.\nDriving Efficiency and Innovation\nThe principles underpinning computational learning theory are fundamental in formulating the blueprint of machine learning algorithms. Understanding these theoretical aspects simplifies the model-building process, driving efficiency and fostering innovation.\nThis, in turn, forms the baseline for designing more complex and productive\nmachine learning models\n, substantiating the field's significance.\nCrucial in Real-world Applications\nEvery subdomain of technology that utilizes\nmachine learning\n, from\nnatural language processing\nto computer vision, health tech to fintech, stands to gain from computational learning theory. The theory accelerates machine learning deployment.\nIt allows researchers to tinker with\nmachine learning algorithms\n, enhancing their efficiency, and making them adept at handling all kinds of data, driving better, practical real-world outcomes.\nReady to build your chatbot? Create your own\nGet Started FREE\nHow does Computational Learning Theory work?\nIn computational theory, most learning is supervised learning. There's a concept or a task that the machine is expected to learn.\nThis concept is surfaced through training examples, which come in pairs. Each pair consists of an '\ninstance\n' and a '\nlabel\n'. Instances are the input the machine receives, and labels are the correct output, the target.\nThe Learning Algorithm's Role\nA learning\nalgorithm\nduring mandatory training makes repetitive slogs, ingesting instance-label pairs. Then, it tries to discern a generalized picture, a pattern that emerges, through the muddle of examples it parses.\nThat generalized picture will enable the machine to determine the labels and the right output for encounters with novel instances, instances it has never been fed before.\nSamples and Hypotheses\nGiven infinite training examples, a machine can learn any concept or computing task, right? Wrong. That's where samples and hypotheses saunter significantly.\nEvery concept class has an associated number of samples beyond which there's no further improvement, no matter if the machine is provided with additional examples.\nThe machine arrives at this optimum through hypotheses, or prediction models, continually updating them to fit the incoming data better and dish out more precise predictions.\nWhen is Computational Learning Theory Applied?\nIf an organizational task revolves around categorizing input data, computational learning theory can greatly aid the process, assisting machines in learning\ncategories\n, or '\nconcepts\n,' and assigning new data inputs to these learned categories.\nPredictive Modeling\nThe realm of predictive modeling, where the primary goal is to use sand dunes of data to divine clear murky crystal balls of future events or future trends, finds an essential ally in computational learning theory.\nResource Allocation\nAllocating resources to collect vital samples or data for\nmachine learning\ncan be a convoluted task.\nComputational learning theory, with its studied focus on the optimal number of examples required for effective learning, can aid in efficient resource allocation, ensuring the right amount of data is gathered for training.\nChallenges in Operationalizing Computational Learning Theory\nComputational Learning Theory, while empowering, is intricate and sophisticated. Not everyone can grasp its complexities with ease. The field requires a deep understanding of mathematics, statistics, and computer science.\nResource-Intensive\nNotably, many learning algorithms that fall under the centrifuge of computational learning theory can be highly resource-intensive, requiring muscular computational horsepower. Limited resources might strain the implementation of these\nalgorithms\n.\nScalability Concerns\nOften, scalability can pose a challenge. Credit to the breathtaking speed at which technology evolves, colossal mounds of data accrue in the blink of an eye. In such situations, the traditional tenets of computational learning theory could falter.\nThe Paradox of Noise\nThere\u2019s also the puzzle of noise. In a utopian vacuum, where every training example the learning algorithm confronts is perfect and accurate, learning is a breeze. But reality is far from a utopia. Data could be noisy, incomplete, inaccurate, or even contradictory.\nBest Practices For Computational Learning Theory (CoLT)\nThese will not only help in enhancing the efficiency and effectiveness of learning algorithms but also ensure that the models developed are robust, generalizable, and capable of performing well across diverse datasets and in various conditions. Here are some detailed best practices:\nUnderstanding the Bias-Variance Tradeoff\nTrade-off Comprehension\nEngaging deeply with the concept of the bias-variance tradeoff is crucial.\nHigh bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting), whereas high variance can make the model perform well on the training data but poorly on any unseen data (overfitting).\nApplication\nImplement techniques that balance this tradeoff effectively.\nFor example\n, increasing the model complexity might decrease bias but increase variance.\nCross-validation\ncan help estimate the model's performance on unseen data, guiding adjustments to reach an optimal balance.\nSuggested Reading:\nDeep Tech\nRegularization\nPenalizing Complexity\nRegularization techniques, such as L1 and L2 regularization, add a penalty to the size of the coefficients in prediction functions to prevent the model from becoming too complex and overfitting the training data.\nPractical Use\nChoose a regularization method based on the problem at hand. L1 regularization can lead to a sparse model where irrelevant features are assigned a weight of zero, useful for feature selection.\nL2 regularization generally results in better prediction accuracy because it keeps all features but penalizes the weights of less important features.\nValidation Techniques\nCross-validation\nImplement\ncross-validation\n, especially k-fold cross-validation, to better estimate the model's ability to generalize to unseen data.\nThis involves dividing your dataset into k smaller sets (or 'folds'), using k-1 of them for training the model and the remaining set for testing, and repeating this process k times with each fold used exactly once as the test set.\nValidation Set\nBesides cross-validation, using a validation set (separate from the testing set) during the training process can help tune model\nparameters\nwithout overfitting the test set. This is crucial for assessing how well the model has generalized.\nAlgorithm Selection and Complexity\nRight Algorithm for the Right Problem\nNot every learning algorithm is suitable for every type of problem. It's essential to understand the strengths and weaknesses of different algorithms and select the one that aligns with the specifics of your task and data.\nConsider Complexity\nBe cautious of the algorithm's complexity in relation to your available computational resources.\nMore complex algorithms, such as\ndeep learning\nmodels, may provide higher accuracy but also require significantly more computational power and data.\nStaying Updated and Mitigating Overfitting\nContinuous Learning\nThe field of computational learning theory is rapidly evolving. Staying updated with the latest research findings,\nalgorithms\n, and techniques is vital for applying the most effective and efficient learning methods.\nStrategies Against Overfitting\nApart from regularization and cross-validation, consider other strategies to prevent overfitting, such as pruning decision trees or using dropout in\nneural networks\n.\nEnsemble methods like bagging and boosting can also help by aggregating the predictions of several models to improve robustness and accuracy.\nWhat? Chatbots Powered by ChatGPT!\nTry BotPenguin\nFrequently Asked Questions (FAQs)\nWhat is the Core Focus of Computational Learning Theory?\nComputational Learning Theory focuses on designing efficient algorithms that can 'learn' from data and make theoretical predictions about their performance.\nHow Does Computational Learning Theory Contribute to Machine Learning?\nIt provides the underpinnings for\nmachine learning\nby quantifying the 'learnability' of tasks and guiding algorithm design and implementation.\nWhat's the Significance of \"PAC Learning\" in Computational Learning Theory?\n\"Probably Approximately Correct\" (PAC) Learning provides a formalized framework to understand and quantify the performance of learning algorithms.\nDo Computational Learning Theory Concepts Impact AI Development?\nYes, the principles and results of Computational Learning Theory guide the development of\nAI\nsystems that adapt and learn from their environment.\nDoes Computational Learning Theory Offer Insights into Human Learning?\nWhile not its primary focus, this theory does offer interesting parallels and can spur discussions around human learning processes and brain computation.\nBuild your first AI chatbot for FREE in just 5 minutes!\nGet Started FREE\nSurprise! BotPenguin has fun blogs too\nWe know you\u2019d love reading them, enjoy and learn.\nWhat is a WhatsApp Campaign? (With Real-World Examples)\nUpdated at Nov 15, 2024\n16 min to read\nBotPenguin\nContent Writer, BotPenguin\nA Comprehensive Look at Generative AI Use Cases Across Industries\nUpdated at Nov 14, 2024\n14 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nHow Generative AI Models Help in Enhancing Chatbot Conversations\nUpdated at Nov 14, 2024\n8 min to read\nManish Goyal\nAI Technical Lead, BotPenguin\nTable of Contents\nWhat is Computational Learning Theory?\nWhy Computational Learning Theory?\nHow does Computational Learning Theory work?\nWhen is Computational Learning Theory Applied?\nChallenges in Operationalizing Computational Learning Theory\nBest Practices For Computational Learning Theory (CoLT)\nFrequently Asked Questions (FAQs)\nBotPenguin is the best AI Chatbot maker platform. Create a Chatbot for WhatsApp, Website, Facebook Messenger, Telegram, WordPress & Shopify with BotPenguin - 100% FREE! Our chatbot creator helps with lead generation, appointment booking, customer support, marketing automation, WhatsApp & Facebook Automation for businesses. AI-powered No-Code chatbot maker with live chat plugin & ChatGPT integration.\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nMobile app\niOS App\nAndroid App\nFully Operational\nStatus\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nPartners\nWhitelabel Partner\nWhatsapp Whitelabel Partner\nImplementation Partner\nAffiliate Partner\nGet Started\nChatbot For Ecommerce\nChatbot For Real Estate\nChatbot For Education\nChatbot For Travel\nAll Templates\nFree Tools\nWhatsApp Link Generator\nWhatsApp QR Code Generator\nOpenAI API Pricing Calculator\nChatbot ROI Calculator\nAll Free Tools\nIntegrations\nChatGPT\nGoHighLevel\nBitrix 24\nZoho CRM\nZapier\nAll Integrations\nResources\nBlogs\nGlossary\nHelp Center\nWrite for us\nContact Us\nWhat\u2019s New\nProduct Updates\nComparisons\nBotPenguin vs Manychat\nBotPenguin vs Tidio\nBotPenguin vs Tawk.to\nBotPenguin vs Wati\nBotPenguin vs Landbot\nAll Comparisons\nAlternatives\nWhat you get\nLead Generation Bot\nSupport Bot\nAssistant Bot\nPlatforms\nMicrosoft Teams\nNew\nInstagram\nNew\nWhatsapp\nTelegram\nFacebook\nWebsites\nGet Started\nIntegrations\nComparisons\nPartners\nFree Tools\nResources\nWhat you get\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nTerms & Conditions\nPrivacy Policy\nSecurity\nGDPR\nRefund Policy\nCopyright \u00a9 2018 - 2024 Relinns Technologies Pvt. Ltd. All RightsReserved.", "embedding": [-0.0822506994009018, -0.07375659048557281, 0.004002957139164209, 0.023637283593416214, -0.00605864729732275, -0.053547970950603485, 0.04016933590173721, 0.06670863181352615, -0.01436522789299488, 0.05876699462532997, 0.03226929157972336, -0.007491655647754669, 0.018905868753790855, 0.023433905094861984, 0.09720674902200699, -0.01630534790456295, 0.08691667765378952, -0.10338997095823288, -0.07690167427062988, -0.02966669388115406, -0.005323860328644514, -0.04624830558896065, 0.0550023689866066, -0.041073277592659, -0.021633174270391464, -0.014021442271769047, -0.028263216838240623, -0.03131880238652229, 5.6569570006104186e-05, -0.06282352656126022, -0.003989857621490955, 0.027838846668601036, -0.00041045842226594687, 0.057948969304561615, -0.03300533443689346, -0.0064244018867611885, -0.03230643272399902, 0.02299799956381321, 0.07868120819330215, -0.04129761829972267, -0.09274239093065262, -0.07764150202274323, -0.058445289731025696, -0.025819892063736916, 0.12328869849443436, 0.015371691435575485, -0.05839699134230614, -0.017849624156951904, -0.01174109522253275, 0.06360924988985062, -0.1187390610575676, -0.06680868566036224, 0.043710820376873016, 0.06578170508146286, -0.06215151771903038, 0.02761187218129635, -0.00919621903449297, 0.013236494734883308, 0.0185600183904171, -0.02540731430053711, -0.05586624890565872, -0.04147486761212349, 0.0287490077316761, 0.042688071727752686, -0.03324572741985321, 0.043498095124959946, -0.11298438161611557, 0.00269192922860384, 0.006640240084379911, -0.030626149848103523, -0.0035178710240870714, 0.007922467775642872, -0.04554777592420578, 0.06495774537324905, 0.03767415136098862, -0.039499565958976746, 0.0015733835753053427, 0.006647820118814707, 0.04009958729147911, -0.057211387902498245, -0.005087053403258324, 0.05874645709991455, -0.010994290933012962, 0.050872888416051865, -0.018650483340024948, -0.02737504430115223, -0.0063152858056128025, 0.047693297266960144, -0.04225528612732887, -0.0156682301312685, 0.04637494310736656, 0.0002175141853513196, 0.023667873814702034, 0.01527430396527052, 0.011797460727393627, 0.013211295939981937, -0.046139203011989594, 0.007775487378239632, -0.05767444521188736, -0.0057380651123821735, -0.020735034719109535, -0.01669802889227867, -0.04962915554642677, -0.0821472555398941, -0.04149870201945305, 0.027414392679929733, 0.04904492199420929, -0.030377930030226707, 0.1512221395969391, -0.03324681147933006, -0.1297604739665985, -0.030063362792134285, -0.010693380609154701, -0.018498312681913376, 0.003886326216161251, 0.04444779083132744, -0.027777455747127533, 0.058199331164360046, 0.14776141941547394, 0.06489898264408112, 0.037248238921165466, 0.055683985352516174, -0.003344080876559019, 0.008411942981183529, 0.055542223155498505, -0.016215501353144646, -0.05557224899530411, 1.0965205995722153e-32, -0.012386448681354523, 0.027807746082544327, -0.059987373650074005, 0.09134791046380997, 0.06113171949982643, 0.003443570574745536, 0.042183153331279755, 0.04378484934568405, -0.0514090396463871, -0.025080418214201927, -0.07205493748188019, 0.0894143208861351, -0.06128934770822525, 0.06925700604915619, 0.05187300965189934, -0.07982246577739716, -0.04130176454782486, 0.011779654771089554, 0.03931238129734993, -0.00658119423314929, 0.10801663249731064, -0.05123867467045784, 0.06277777254581451, 0.05567336082458496, 0.10626164823770523, 0.03052995353937149, 0.07035738974809647, 0.04201202467083931, 0.05856063961982727, 0.037308402359485626, -0.0917070284485817, 0.013781672343611717, -0.09248143434524536, 0.019096922129392624, -0.0287325456738472, -0.050443120300769806, -0.02272077277302742, -0.1093650683760643, -0.05136388912796974, 0.01519016083329916, -0.1290808767080307, -0.0011690575629472733, -0.05505470559000969, -0.0788726657629013, 0.026637790724635124, 0.012678337283432484, 0.04583970829844475, -0.004895533435046673, 0.01417005155235529, 0.03240387886762619, -0.048511553555727005, 0.003727674251422286, 0.038445428013801575, 0.015970364212989807, 0.001617332804016769, -0.01617792248725891, 0.04019073024392128, -0.040919844061136246, -0.019825415685772896, -0.011897447519004345, -0.004044657107442617, -0.02535914070904255, -0.014495017938315868, -0.0066718957386910915, 0.03767692297697067, 0.03201648220419884, 0.05863836035132408, 0.02423449605703354, 0.06496747583150864, 0.014669332653284073, 0.04568463936448097, 0.0569700188934803, -0.03893648087978363, 0.022331351414322853, -0.0281362347304821, -0.007821442559361458, -0.0881282240152359, 0.0106958681717515, -0.03276320919394493, 0.01255535427480936, -0.012892100028693676, -0.012998094782233238, -0.006174480076879263, -0.054139211773872375, 0.03157385066151619, -0.05876435339450836, 0.02873372659087181, -0.04907340928912163, -0.02317078225314617, 0.03260772302746773, -0.0549420490860939, 0.06278394162654877, -0.07066910713911057, 0.08918716758489609, -0.040650129318237305, -9.172905514452425e-33, -0.04420486465096474, 0.010150988586246967, -0.06429190933704376, 0.10804358124732971, 0.012079242616891861, -0.021253028884530067, 0.04006321355700493, -0.04853496700525284, 0.08937618136405945, -0.04094356670975685, -0.08833944797515869, -0.0004907489637844265, 0.007347614038735628, -0.0053288438357412815, -0.009732837788760662, 0.030957702547311783, -0.08386246114969254, -0.027916472405195236, 0.03078288398683071, 0.0016173790208995342, -0.03150595724582672, 0.04931195080280304, -0.12705153226852417, 0.013093100860714912, 0.014563369564712048, 0.04566122218966484, -0.07499495893716812, 0.06089644506573677, 0.031412605196237564, 0.06870763748884201, -0.03035767562687397, -0.014593490399420261, -0.024179667234420776, 0.005117801483720541, 0.013096608221530914, 0.07058372348546982, 0.01880561001598835, -0.009084803983569145, -0.013474930077791214, -0.03146602585911751, 0.10737074166536331, -0.06912432610988617, -0.04877797141671181, -0.09501282870769501, 0.008728778921067715, 0.02528773806989193, -0.14641828835010529, -0.023080119863152504, -0.0312960222363472, 0.04646395891904831, 0.06116684153676033, 0.021940132603049278, 0.03664865717291832, -0.07083621621131897, -0.09636926651000977, -0.017802651971578598, 0.09546113759279251, 0.015149244107306004, -0.08501330018043518, 0.009154506027698517, 0.018439529463648796, -0.007489638868719339, 0.07236015051603317, 0.08073970675468445, 0.01378000807017088, -0.01467848103493452, 0.031123772263526917, 0.04347110539674759, -0.008695215918123722, -0.09442935883998871, 0.0485023632645607, -0.0267670638859272, -0.01701057329773903, -0.01532907783985138, 0.004225530661642551, 0.08557100594043732, 0.029778679832816124, -0.08787265419960022, -0.032766953110694885, -0.016822339966893196, -0.030980225652456284, -0.0108945332467556, 0.05350426957011223, 0.06570004671812057, -0.08548714965581894, 0.0790000706911087, -0.008057724684476852, 0.0034779629204422235, -0.017542345449328423, -0.024439483880996704, -0.04159976914525032, 0.042527493089437485, -0.02174854651093483, 0.09601261466741562, -0.018036818131804466, -6.049527456752912e-08, -0.03586798161268234, -0.02855137549340725, 0.06964977830648422, 0.03174257650971413, 0.06479514390230179, -0.04062764346599579, -0.04037634655833244, 0.0686909556388855, -0.0077634332701563835, 0.033340051770210266, 0.008410647511482239, 0.0005779840867035091, -0.030430540442466736, 0.06468845158815384, 0.08006060123443604, 0.020647570490837097, 0.0025722533464431763, -0.046045515686273575, 0.005203668028116226, -0.03634686395525932, 0.09537085145711899, -0.006630244664847851, -0.026635728776454926, -0.020137926563620567, 0.0184443648904562, -0.08912760764360428, -0.06522152572870255, 0.08523228019475937, -0.046562664210796356, 0.00736305583268404, -0.0267026349902153, -0.032202038913965225, 0.05681256577372551, -0.04457980766892433, 0.03301311284303665, 0.01695847697556019, -0.04405495151877403, -0.1014183983206749, 0.010343302972614765, 0.03553445637226105, -0.0165157001465559, 0.026301540434360504, 0.02259744517505169, -0.078704334795475, -0.00430285045877099, -0.04682318493723869, -0.07578996568918228, -0.12335296720266342, 0.04315615072846413, 0.010950672440230846, -0.03407946974039078, 0.037072956562042236, 0.027664348483085632, 0.030520278960466385, 0.09911362081766129, 0.0005834407056681812, 0.05152403563261032, -0.027246080338954926, 0.06652464717626572, 0.13597406446933746, 0.028715481981635094, 0.0271671824157238, 0.032184988260269165, 0.04492558538913727]}